{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data = pd.read_parquet('chiller_data_pre.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data['new_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(chiller_data, x=chiller_data.index, y=['plant_target_chw_setpoint','chilled_water_loop_supply_water_temperature'],\n",
    "              labels={'value': 'Temperature (°C)', 'variable': 'Temperature Type'},\n",
    "              title='Setpoint vs CHWS Temperature')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chiller cooling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "corr_metrix = chiller_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chiller_cooling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chiller_id in range (1,6):\n",
    "    main_feature = f'chiller_{chiller_id}_cooling_rate'\n",
    "    excluded_keywords = [f'chiller_{i}' for i in range(1, 6) if i != chiller_id] + \\\n",
    "                        ['cdp_', 'chp_', 'ct']\n",
    "    exclude_features = [col for col in chiller_data.columns if any(keyword in col for keyword in excluded_keywords)]\n",
    "    correlations = corr_metrix[main_feature].drop(exclude_features).drop(main_feature)\n",
    "    top_20_correlations = correlations.abs().sort_values(ascending=False).head(20)\n",
    "    fig = px.bar(top_20_correlations, x=top_20_correlations.index, y=top_20_correlations.values, title=f'Top 20 Correlations with {main_feature}', labels={'x':'Features', 'y':'Correlation'})\n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()\n",
    "    # Print the top 20 correlations for reference\n",
    "    print(f\"Top 20 Correlations with {main_feature}:\")\n",
    "    print(top_20_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chiller_cond_leaving_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chiller_id in range (1,6):\n",
    "    main_feature = f'chiller_{chiller_id}_cond_leaving_water_temperature'\n",
    "    excluded_keywords = [f'chiller_{i}' for i in range(1, 6) if i != chiller_id] + \\\n",
    "                        ['cdp_', 'chp_', 'ct']\n",
    "    exclude_features = [col for col in chiller_data.columns if any(keyword in col for keyword in excluded_keywords)]\n",
    "    correlations = corr_metrix[main_feature].drop(exclude_features).drop(main_feature)\n",
    "    top_20_correlations = correlations.abs().sort_values(ascending=False).head(20)\n",
    "    fig = px.bar(top_20_correlations, x=top_20_correlations.index, y=top_20_correlations.values, title=f'Top 20 Correlations with {main_feature}', labels={'x':'Features', 'y':'Correlation'})\n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()\n",
    "    # Print the top 20 correlations for reference\n",
    "    print(f\"Top 20 Correlations with {main_feature}:\")\n",
    "    print(top_20_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "for chiller_id in range (1,6):\n",
    "    chiller_data_i = chiller_data.copy()\n",
    "    chiller_data_i #drop row that status_read = 0\n",
    "    chillers_feature = [f'chiller_{chiller_id}_evap_leaving_water_temperature',\n",
    "            f'chiller_{chiller_id}_evap_water_flow_rate',\n",
    "            f'chiller_{chiller_id}_cond_water_flow_rate',\n",
    "            f'chiller_{chiller_id}_status_read',\n",
    "            'outdoor_weather_station_wetbulb_temperature',\n",
    "            'outdoor_weather_station_drybulb_temperature',\n",
    "            'outdoor_weather_station_relative_humidity']\n",
    "    \n",
    "    chillers_target = [f'chiller_{chiller_id}_cooling_rate']\n",
    "\n",
    "    X = chiller_data[chillers_feature]\n",
    "    y = chiller_data[chillers_target]\n",
    "\n",
    "    train_size = int(0.6 * len(X))\n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_test, y_test = X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Function to train and evaluate MLP model\n",
    "def train_and_evaluate_mlp(chiller_id, data, save_path):\n",
    "\n",
    "    chillers_feature = [\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate',\n",
    "    ]\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_squared'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] ** 2\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] * data[f'chiller_{chiller_id}_cond_water_flow_rate']\n",
    "    data[f'chiller_{chiller_id}_cond_water_flow_rate_squared'] = data[f'chiller_{chiller_id}_cond_water_flow_rate'] ** 2\n",
    "\n",
    "    # Add new features to the feature list\n",
    "    chillers_feature.extend([\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_squared',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate_squared',\n",
    "    ])\n",
    "\n",
    "    chillers_target = [f'chiller_{chiller_id}_cooling_rate']\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chiller_data_i = data[(data[f'chiller_{chiller_id}_status_read'] != 0)].copy()\n",
    "    chiller_data_i = chiller_data_i[(chiller_data_i[chillers_feature + chillers_target] != 0).all(axis=1)]\n",
    "\n",
    "    X = chiller_data_i[chillers_feature]\n",
    "    y = chiller_data_i[chillers_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the MLP model\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(200,), max_iter=2000, random_state=42)\n",
    "    mlp_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Predict\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Chiller {chiller_id} - MLP Regression MSE: {mse_mlp}\")\n",
    "    print(f\"Chiller {chiller_id} - MLP Regression MAE: {mae_mlp}\")\n",
    "    print(f\"Chiller {chiller_id} - MLP Regression R²: {r2_mlp}\")\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_mlp_df = pd.DataFrame(y_pred_mlp, index=y_test.index, columns=y_test.columns)\n",
    "    fig = px.line(x=X_test.index, y=y_pred_mlp_df[chillers_target[0]], title=f'Chiller {chiller_id} - {chillers_target[0]}')\n",
    "    fig.update_traces(line_color='red', name=f'{chillers_target[0]} Prediction')\n",
    "    fig.add_trace(px.line(x=X_test.index, y=y_test[chillers_target[0]]).data[0])\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chillers_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/cooling_rate_model/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/cooling_rate_model/chiller_{chiller_id}_{chillers_target[0]}_prediction.html\")\n",
    "\n",
    "    # Permutation Feature Importance\n",
    "    perm_importance = permutation_importance(mlp_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "    # Plot Permutation Importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_test.columns[sorted_idx],\n",
    "        'Importance': perm_importance.importances_mean[sorted_idx]\n",
    "    })\n",
    "\n",
    "    fig_importance = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "                            title=f'Chiller {chiller_id} - Feature Importance')\n",
    "    fig_importance.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    fig_importance.write_image(f\"{save_path}/feature_importance/chiller_{chiller_id}_feature_importance.png\")\n",
    "\n",
    "# Loop through each chiller and perform the MLP analysis\n",
    "save_path = \"../visualizations\"  # Set your desired save path\n",
    "for chiller_id in range(1, 6):\n",
    "    train_and_evaluate_mlp(chiller_id, chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Function to train and evaluate Linear Regression model\n",
    "def train_and_evaluate_linear_regression(chiller_id, data, save_path):\n",
    "\n",
    "    chillers_feature = [\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate',\n",
    "    ]\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_squared'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] ** 2\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] * data[f'chiller_{chiller_id}_cond_water_flow_rate']\n",
    "    data[f'chiller_{chiller_id}_cond_water_flow_rate_squared'] = data[f'chiller_{chiller_id}_cond_water_flow_rate'] ** 2\n",
    "\n",
    "    # Add new features to the feature list\n",
    "    chillers_feature.extend([\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_squared',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate_squared',\n",
    "    ])\n",
    "\n",
    "    chillers_target = [f'chiller_{chiller_id}_cooling_rate']\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chiller_data_i = data[(data[f'chiller_{chiller_id}_status_read'] != 0)].copy()\n",
    "    chiller_data_i = chiller_data_i[(chiller_data_i[chillers_feature + chillers_target] != 0).all(axis=1)]\n",
    "\n",
    "    X = chiller_data_i[chillers_feature]\n",
    "    y = chiller_data_i[chillers_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "    r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Chiller {chiller_id} - Linear Regression MSE: {mse_lr}\")\n",
    "    print(f\"Chiller {chiller_id} - Linear Regression MAE: {mae_lr}\")\n",
    "    print(f\"Chiller {chiller_id} - Linear Regression R²: {r2_lr}\")\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_lr_df = pd.DataFrame(y_pred_lr, index=y_test.index, columns=y_test.columns)\n",
    "    fig = px.line(x=X_test.index, y=y_pred_lr_df[chillers_target[0]], title=f'Chiller {chiller_id} - {chillers_target[0]}')\n",
    "    fig.update_traces(line_color='red', name=f'{chillers_target[0]} Prediction')\n",
    "    fig.add_trace(px.line(x=X_test.index, y=y_test[chillers_target[0]]).data[0])\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chillers_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/cooling_rate_model/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/cooling_rate_model_lr/chiller_{chiller_id}_{chillers_target[0]}_prediction.html\")\n",
    "\n",
    "    # Permutation Feature Importance\n",
    "    perm_importance = permutation_importance(lr_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "    # Plot Permutation Importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_test.columns[sorted_idx],\n",
    "        'Importance': perm_importance.importances_mean[sorted_idx]\n",
    "    })\n",
    "\n",
    "    fig_importance = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "                            title=f'Chiller {chiller_id} - Feature Importance')\n",
    "    fig_importance.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    fig_importance.write_image(f\"{save_path}/feature_importance/chiller_{chiller_id}_feature_importance.png\")\n",
    "\n",
    "# Loop through each chiller and perform the Linear Regression analysis\n",
    "save_path = \"../visualizations\"  # Set your desired save path\n",
    "for chiller_id in range(1, 6):\n",
    "    train_and_evaluate_linear_regression(chiller_id, chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chiller power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to train and evaluate Linear Regression model\n",
    "def train_and_evaluate_linear_regression(chiller_id, data, save_path):\n",
    "    \n",
    "    chillers_feature = [\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cooling_rate'\n",
    "    ]\n",
    "\n",
    "    feature_mapping = {\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature': 'CHST',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate': 'CHWF',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate': 'CDWF',\n",
    "        f'chiller_{chiller_id}_cooling_rate': 'CR',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_squared': 'CHST²',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow': 'CHST*CDWF',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate_squared': 'CDWF²',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate_squared': 'CHWF²',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_evap_water_flow_rate': 'CHST*CHWF',\n",
    "        f'chiller_{chiller_id}_cooling_rate_squared': 'CR²'\n",
    "    }\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_squared'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] ** 2\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] * data[f'chiller_{chiller_id}_cond_water_flow_rate']\n",
    "    data[f'chiller_{chiller_id}_cond_water_flow_rate_squared'] = data[f'chiller_{chiller_id}_cond_water_flow_rate'] ** 2\n",
    "    data[f'chiller_{chiller_id}_evap_water_flow_rate_squared'] = data[f'chiller_{chiller_id}_evap_water_flow_rate'] ** 2\n",
    "    data[f'chiller_{chiller_id}_evap_leaving_water_temperature_evap_water_flow_rate'] = data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] * data[f'chiller_{chiller_id}_evap_water_flow_rate']\n",
    "    data[f'chiller_{chiller_id}_cooling_rate_squared'] = data[f'chiller_{chiller_id}_cooling_rate'] ** 2\n",
    "    # Add new features to the feature list\n",
    "    chillers_feature.extend([\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_squared',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate_squared',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate_squared',\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature_evap_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cooling_rate_squared'\n",
    "    ])\n",
    "\n",
    "    chillers_target = [f'chiller_{chiller_id}_power']\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chiller_data_i = data[(data[f'chiller_{chiller_id}_status_read'] != 0)].copy()\n",
    "    chiller_data_i = chiller_data_i[(chiller_data_i[chillers_feature + chillers_target] != 0).all(axis=1)]\n",
    "\n",
    "    X = chiller_data_i[chillers_feature]\n",
    "    y = chiller_data_i[chillers_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(lr_model, f\"{save_path}/models/chiller_{chiller_id}_linear_regression_model.pkl\")\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/chiller_{chiller_id}_linear_regression_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "    r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Chiller {chiller_id} - Linear Regression MSE: {mse_lr}\")\n",
    "    print(f\"Chiller {chiller_id} - Linear Regression MAE: {mae_lr}\")\n",
    "    print(f\"Chiller {chiller_id} - Linear Regression R²: {r2_lr}\")\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_lr_df = pd.DataFrame(y_pred_lr, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[chillers_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_lr_df[chillers_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'Chiller {chiller_id} - {chillers_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chillers_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/chiller_{chiller_id}_{chillers_target[0]}_prediction.html\")\n",
    "\n",
    "    # Correlation Coefficients\n",
    "    correlation_matrix = data[chillers_feature + chillers_target].corr()\n",
    "    correlation_with_target = correlation_matrix[chillers_target[0]].drop(chillers_target[0]).sort_values(ascending=True)\n",
    "\n",
    "    # Plot Correlation Coefficients\n",
    "    # Map long feature names to shorter names\n",
    "    correlation_with_target.index = [feature_mapping.get(feat, feat) for feat in correlation_with_target.index]\n",
    "    \n",
    "    fig_corr = px.bar(x=correlation_with_target.values, y=correlation_with_target.index, orientation='h',\n",
    "                      title=f'Chiller {chiller_id} - Correlation Coefficients')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/chiller_{chiller_id}_feature_importance.png\")\n",
    "\n",
    "# Loop through each chiller and perform the Linear Regression analysis\n",
    "save_path = \"../visualizations/power_model_lr\"  # Set your desired save path\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "for chiller_id in range(1, 6):\n",
    "    train_and_evaluate_linear_regression(chiller_id, chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate Random Forest model\n",
    "def train_and_evaluate_random_forest(chiller_id, data, save_path):\n",
    "    \n",
    "    chillers_feature = [\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cooling_rate'\n",
    "    ]\n",
    "\n",
    "    chillers_target = [f'chiller_{chiller_id}_power']\n",
    "\n",
    "    feature_mapping = {\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature': 'CHST',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate': 'CHWF',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate': 'CDWF',\n",
    "        f'chiller_{chiller_id}_cooling_rate': 'CR',\n",
    "    }\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chiller_data_i = data[(data[f'chiller_{chiller_id}_status_read'] != 0)].copy()\n",
    "    chiller_data_i = chiller_data_i[(chiller_data_i[chillers_feature + chillers_target] != 0).all(axis=1)]\n",
    "\n",
    "    X = chiller_data_i[chillers_feature]\n",
    "    y = chiller_data_i[chillers_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestRegressor()\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    joblib.dump(rf_model, f\"{save_path}/models/chiller_{chiller_id}_random_forest_model.pkl\")\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/chiller_{chiller_id}_random_forest_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Chiller {chiller_id} - Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Chiller {chiller_id} - Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Chiller {chiller_id} - Random Forest R²: {r2_rf}\")\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_rf_df = pd.DataFrame(y_pred_rf, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[chillers_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_rf_df[chillers_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'Chiller {chiller_id} - {chillers_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chillers_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/chiller_{chiller_id}_{chillers_target[0]}_prediction.html\")\n",
    "\n",
    "    # Feature Importances\n",
    "    feature_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
    "    feature_importances = feature_importances.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    feature_importances.index = feature_importances.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr = px.bar(x=feature_importances.values, y=feature_importances.index, orientation='h',\n",
    "                      title=f'Chiller {chiller_id} - Feature Importances')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/chiller_{chiller_id}_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = chiller_data_i[chillers_feature + chillers_target].corr()\n",
    "    corr_target = corr_matrix[chillers_target[0]].drop(chillers_target[0])  # Drop the target's correlation with itself\n",
    "    corr_target = corr_target.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    corr_target.index = corr_target.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'Chiller {chiller_id} - Feature Correlation with {chillers_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/chiller_{chiller_id}_correlation_coefficient.png\")\n",
    "\n",
    "# Loop through each chiller and perform the Random Forest analysis\n",
    "save_path = \"../visualizations/power_model_rf\"  # Set your desired save path\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "for chiller_id in range(1, 6):\n",
    "    train_and_evaluate_random_forest(chiller_id, chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate MLP model\n",
    "def train_and_evaluate_mlp(chiller_id, data, save_path):\n",
    "    \n",
    "    chillers_feature = [\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate',\n",
    "        f'chiller_{chiller_id}_cooling_rate'\n",
    "    ]\n",
    "\n",
    "    chillers_target = [f'chiller_{chiller_id}_power']\n",
    "\n",
    "    feature_mapping = {\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature': 'CHST',\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate': 'CHWF',\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate': 'CDWF',\n",
    "        f'chiller_{chiller_id}_cooling_rate': 'CR',\n",
    "    }\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chiller_data_i = data[(data[f'chiller_{chiller_id}_status_read'] != 0)].copy()\n",
    "    chiller_data_i = chiller_data_i[(chiller_data_i[chillers_feature + chillers_target] != 0).all(axis=1)]\n",
    "\n",
    "    X = chiller_data_i[chillers_feature]\n",
    "    y = chiller_data_i[chillers_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the MLP model\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(100,100), max_iter=500)\n",
    "    mlp_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    joblib.dump(mlp_model, f\"{save_path}/models/chiller_{chiller_id}_mlp_model.pkl\")\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/chiller_{chiller_id}_mlp_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Chiller {chiller_id} - MLP MSE: {mse_mlp}\")\n",
    "    print(f\"Chiller {chiller_id} - MLP MAE: {mae_mlp}\")\n",
    "    print(f\"Chiller {chiller_id} - MLP R²: {r2_mlp}\")\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_mlp_df = pd.DataFrame(y_pred_mlp, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[chillers_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_mlp_df[chillers_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'Chiller {chiller_id} - {chillers_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chillers_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/chiller_{chiller_id}_{chillers_target[0]}_prediction.html\")\n",
    "\n",
    "    # Feature Importances (For MLP, we can use permutation importance as a proxy for feature importance)\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    perm_importance = permutation_importance(mlp_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    feature_importances = pd.Series(perm_importance.importances_mean, index=X_train.columns)\n",
    "    feature_importances = feature_importances.sort_values(ascending=True)\n",
    "    feature_importances.index = feature_importances.index.map(feature_mapping)\n",
    "    fig_corr = px.bar(x=feature_importances.values, y=feature_importances.index, orientation='h',\n",
    "                      title=f'Chiller {chiller_id} - Feature Importances')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/chiller_{chiller_id}_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = chiller_data_i[chillers_feature + chillers_target].corr()\n",
    "    corr_target = corr_matrix[chillers_target[0]].drop(chillers_target[0])  # Drop the target's correlation with itself\n",
    "    corr_target = corr_target.sort_values(ascending=True)\n",
    "\n",
    "    corr_target.index = corr_target.index.map(feature_mapping)\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'Chiller {chiller_id} - Feature Correlation with {chillers_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/chiller_{chiller_id}_correlation_coefficient.png\")\n",
    "\n",
    "# Loop through each chiller and perform the MLP analysis\n",
    "save_path = \"../visualizations/power_model_mlp\"  # Set your desired save path\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "for chiller_id in range(1, 6):\n",
    "    train_and_evaluate_mlp(chiller_id, chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMIAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate Linear Regression model for CHP\n",
    "def train_and_evaluate_linear_regression_chp(chiller_data, save_path):\n",
    "\n",
    "    chp_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'chilled_water_loop_flow_rate'\n",
    "    ]\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    chiller_data['chilled_water_loop_flow_rate_squared'] = chiller_data['chilled_water_loop_flow_rate'] ** 2\n",
    "    chiller_data['chilled_water_loop_flow_rate_cubed'] = chiller_data['chilled_water_loop_flow_rate'] ** 3\n",
    "\n",
    "    # Add new features to the feature list\n",
    "    chp_features.extend([\n",
    "        'chilled_water_loop_flow_rate_squared',\n",
    "        'chilled_water_loop_flow_rate_cubed',\n",
    "    ])\n",
    "\n",
    "    chp_target = ['plant_power_all_chps']\n",
    "\n",
    "    feature_mapping = {\n",
    "        'plant_cooling_rate': 'PCR',\n",
    "        'chilled_water_loop_flow_rate': 'PCHWF',\n",
    "        'chilled_water_loop_flow_rate_squared': 'PCHWF²',\n",
    "        'chilled_water_loop_flow_rate_cubed': 'PCHWF³',\n",
    "    }\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_chps' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_chps'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chp_data_filtered = chiller_data_filtered[(chiller_data_filtered[chp_features + chp_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = chp_data_filtered[chp_features]\n",
    "    y = chp_data_filtered[chp_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"chp_linear_regression_model.pkl\")\n",
    "    joblib.dump(lr_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/chp_linear_regression_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "    r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CHP - Linear Regression MSE:\", mse_lr)\n",
    "    print(\"CHP - Linear Regression MAE:\", mae_lr)\n",
    "    print(\"CHP - Linear Regression R²:\", r2_lr)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_lr_df = pd.DataFrame(y_pred_lr, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[chp_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_lr_df[chp_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CHP - {chp_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chp_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/chp_{chp_target[0]}_prediction.html\")\n",
    "\n",
    "    # # Feature Importances\n",
    "    # feature_importances = pd.Series(lr_model.feature_importances_, index=X_train.columns)\n",
    "    # feature_importances = feature_importances.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    # feature_importances.index = feature_importances.index.map(feature_mapping)\n",
    "\n",
    "    # fig_corr = px.bar(x=feature_importances.values, y=feature_importances.index, orientation='h',\n",
    "    #                   title=f'CHP - Feature Importances')\n",
    "    # fig_corr.update_layout(\n",
    "    #     xaxis_title='Importance',\n",
    "    #     yaxis_title='Feature'\n",
    "    # )\n",
    "\n",
    "    # # Ensure the directory exists for saving plots\n",
    "    # os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    # fig_corr.write_image(f\"{save_path}/feature/chp_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = chp_data_filtered[chp_features + chp_target].corr()\n",
    "    corr_target = corr_matrix[chp_target[0]].drop(chp_target[0])  # Drop the target's correlation with itself\n",
    "    corr_target = corr_target.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    corr_target.index = corr_target.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'CHP - Feature Correlation with {chp_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/chp_correlation_coefficient.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/chp_power_model_lr\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate Linear Regression model for the CHP power prediction\n",
    "train_and_evaluate_linear_regression_chp(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate Random Forest model for CHP\n",
    "def train_and_evaluate_random_forest_chp(chiller_data, save_path):\n",
    "\n",
    "    chp_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'chilled_water_loop_flow_rate'\n",
    "    ]\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    chiller_data['chilled_water_loop_flow_rate_squared'] = chiller_data['chilled_water_loop_flow_rate'] ** 2\n",
    "    chiller_data['chilled_water_loop_flow_rate_cubed'] = chiller_data['chilled_water_loop_flow_rate'] ** 3\n",
    "\n",
    "    # Add new features to the feature list\n",
    "    chp_features.extend([\n",
    "        'chilled_water_loop_flow_rate_squared',\n",
    "        'chilled_water_loop_flow_rate_cubed',\n",
    "    ])\n",
    "\n",
    "    feature_mapping = {\n",
    "        'plant_cooling_rate': 'PCR',\n",
    "        'chilled_water_loop_flow_rate': 'PCHWF',\n",
    "        'chilled_water_loop_flow_rate_squared': 'PCHWF²',\n",
    "        'chilled_water_loop_flow_rate_cubed': 'PCHWF³',\n",
    "    }\n",
    "\n",
    "    chp_target = ['plant_power_all_chps']\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_chps' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_chps'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    chp_data_filtered = chiller_data_filtered[(chiller_data_filtered[chp_features + chp_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = chp_data_filtered[chp_features]\n",
    "    y = chp_data_filtered[chp_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"chp_random_forest_model.pkl\")\n",
    "    joblib.dump(rf_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/chp_random_forest_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CHP - Random Forest MSE:\", mse_rf)\n",
    "    print(\"CHP - Random Forest MAE:\", mae_rf)\n",
    "    print(\"CHP - Random Forest R²:\", r2_rf)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_rf_df = pd.DataFrame(y_pred_rf, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[chp_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_rf_df[chp_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CHP - {chp_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chp_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/chp_{chp_target[0]}_prediction.html\")\n",
    "\n",
    "    # Feature Importances\n",
    "    feature_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
    "    feature_importances = feature_importances.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    feature_importances.index = feature_importances.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr = px.bar(x=feature_importances.values, y=feature_importances.index, orientation='h',\n",
    "                      title=f'CHP - Feature Importances')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/chp_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = chp_data_filtered[chp_features + chp_target].corr()\n",
    "    corr_target = corr_matrix[chp_target[0]].drop(chp_target[0])  # Drop the target's correlation with itself\n",
    "    corr_target = corr_target.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    corr_target.index = corr_target.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'CHP - Feature Correlation with {chp_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/chp_correlation_coefficient.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/chp_power_model_rf\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate Random Forest model for the CHP power prediction\n",
    "train_and_evaluate_random_forest_chp(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate MLP model for CHP\n",
    "def train_and_evaluate_mlp_chp(chiller_data, save_path):\n",
    "\n",
    "    chp_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'chilled_water_loop_flow_rate'\n",
    "    ]\n",
    "\n",
    "    chp_target = ['plant_power_all_chps']\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_chps' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_chps'] != 0]\n",
    "\n",
    "    X = chiller_data_filtered[chp_features]\n",
    "    y = chiller_data_filtered[chp_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the MLP model\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=500, random_state=42)\n",
    "    mlp_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"chp_mlp_model.pkl\")\n",
    "    joblib.dump(mlp_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/chp_mlp_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CHP - MLP MSE:\", mse_mlp)\n",
    "    print(\"CHP - MLP MAE:\", mae_mlp)\n",
    "    print(\"CHP - MLP R²:\", r2_mlp)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_mlp_df = pd.DataFrame(y_pred_mlp, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[chp_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_mlp_df[chp_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CHP - {chp_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{chp_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/chp_{chp_target[0]}_prediction.html\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = chiller_data_filtered[chp_features + chp_target].corr()\n",
    "    corr_target = corr_matrix[chp_target[0]].drop(chp_target[0])  # Drop the target's correlation with itself\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'CHP - Feature Correlation with {chp_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/chp_correlation_coefficient.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/chp_power_model_mlp\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate MLP model for the CHP power prediction\n",
    "train_and_evaluate_mlp_chp(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate Linear Regression model for CDP\n",
    "def train_and_evaluate_linear_regression_cdp(chiller_data, save_path):\n",
    "\n",
    "    cdp_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'condenser_water_loop_flow_rate'\n",
    "    ]\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    chiller_data['condenser_water_loop_flow_rate_squared'] = chiller_data['condenser_water_loop_flow_rate'] ** 2\n",
    "    chiller_data['condenser_water_loop_flow_rate_cubed'] = chiller_data['condenser_water_loop_flow_rate'] ** 3\n",
    "\n",
    "    # Add new features to the feature list\n",
    "    cdp_features.extend([\n",
    "        'condenser_water_loop_flow_rate_squared',\n",
    "        'condenser_water_loop_flow_rate_cubed',\n",
    "    ])\n",
    "\n",
    "    cdp_target = ['plant_power_all_cdps']\n",
    "\n",
    "    feature_mapping = {\n",
    "        'plant_cooling_rate': 'PCR',\n",
    "        'condenser_water_loop_flow_rate': 'PCDWF',\n",
    "        'condenser_water_loop_flow_rate_squared': 'PCDWF²',\n",
    "        'condenser_water_loop_flow_rate_cubed': 'PCDWF³',\n",
    "    }\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_cdps' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_cdps'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    cdp_data_filtered = chiller_data_filtered[(chiller_data_filtered[cdp_features + cdp_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = cdp_data_filtered[cdp_features]\n",
    "    y = cdp_data_filtered[cdp_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"cdp_linear_regression_model.pkl\")\n",
    "    joblib.dump(lr_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/cdp_linear_regression_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "    r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CDP - Linear Regression MSE:\", mse_lr)\n",
    "    print(\"CDP - Linear Regression MAE:\", mae_lr)\n",
    "    print(\"CDP - Linear Regression R²:\", r2_lr)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_lr_df = pd.DataFrame(y_pred_lr, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[cdp_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_lr_df[cdp_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CDP - {cdp_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{cdp_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/cdp_{cdp_target[0]}_prediction.html\")\n",
    "\n",
    "    # Permutation Feature Importance\n",
    "    perm_importance = permutation_importance(lr_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "    # Plot Permutation Importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_test.columns[sorted_idx],\n",
    "        'Importance': perm_importance.importances_mean[sorted_idx]\n",
    "    })\n",
    "\n",
    "    fig_importance = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "                            title='CDP - Feature Importance')\n",
    "    fig_importance.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_importance.write_image(f\"{save_path}/feature/cdp_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = cdp_data_filtered[cdp_features + cdp_target].corr()\n",
    "    corr_target = corr_matrix[cdp_target[0]].drop(cdp_target[0])  # Drop the target's correlation with itself\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'CDP - Feature Correlation with {cdp_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/cdp_feature_correlation.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/cdp_power_model_lr\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate Linear Regression model for the CDP power prediction\n",
    "train_and_evaluate_linear_regression_cdp(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate Random Forest model for CDP\n",
    "def train_and_evaluate_random_forest_cdp(chiller_data, save_path):\n",
    "\n",
    "    cdp_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'condenser_water_loop_flow_rate'\n",
    "    ]\n",
    "    \n",
    "    # Add new features to the dataset\n",
    "    chiller_data['condenser_water_loop_flow_rate_squared'] = chiller_data['condenser_water_loop_flow_rate'] ** 2\n",
    "    chiller_data['condenser_water_loop_flow_rate_cubed'] = chiller_data['condenser_water_loop_flow_rate'] ** 3\n",
    "\n",
    "    # Add new features to the feature list\n",
    "    cdp_features.extend([\n",
    "        'condenser_water_loop_flow_rate_squared',\n",
    "        'condenser_water_loop_flow_rate_cubed',\n",
    "    ])\n",
    "\n",
    "    cdp_target = ['plant_power_all_cdps']\n",
    "\n",
    "    feature_mapping = {\n",
    "        'plant_cooling_rate': 'PCR',\n",
    "        'condenser_water_loop_flow_rate': 'PCDWF',\n",
    "        'condenser_water_loop_flow_rate_squared': 'PCDWF²',\n",
    "        'condenser_water_loop_flow_rate_cubed': 'PCDWF³',\n",
    "    }\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_cdps' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_cdps'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    cdp_data_filtered = chiller_data_filtered[(chiller_data_filtered[cdp_features + cdp_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = cdp_data_filtered[cdp_features]\n",
    "    y = cdp_data_filtered[cdp_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"cdp_random_forest_model.pkl\")\n",
    "    joblib.dump(rf_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/cdp_random_forest_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CDP - Random Forest MSE:\", mse_rf)\n",
    "    print(\"CDP - Random Forest MAE:\", mae_rf)\n",
    "    print(\"CDP - Random Forest R²:\", r2_rf)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_rf_df = pd.DataFrame(y_pred_rf, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[cdp_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_rf_df[cdp_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CDP - {cdp_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{cdp_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/cdp_{cdp_target[0]}_prediction.html\")\n",
    "\n",
    "    # Feature Importances\n",
    "    feature_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
    "    feature_importances = feature_importances.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    feature_importances.index = feature_importances.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr = px.bar(x=feature_importances.values, y=feature_importances.index, orientation='h',\n",
    "                      title=f'CDP - Feature Importances')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/chp_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = cdp_data_filtered[cdp_features + cdp_target].corr()\n",
    "    corr_target = corr_matrix[cdp_target[0]].drop(cdp_target[0])  # Drop the target's correlation with itself\n",
    "    corr_target = corr_target.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    corr_target.index = corr_target.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'CDP - Feature Correlation with {cdp_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/cdp_feature_correlation.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/cdp_power_model_rf\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate Random Forest model for the CDP power prediction\n",
    "train_and_evaluate_random_forest_cdp(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to train and evaluate MLP model for CDP\n",
    "def train_and_evaluate_mlp_cdp(chiller_data, save_path):\n",
    "\n",
    "    cdp_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'condenser_water_loop_flow_rate'\n",
    "    ]\n",
    "\n",
    "    cdp_target = ['plant_power_all_cdps']\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_cdps' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_cdps'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    cdp_data_filtered = chiller_data_filtered[(chiller_data_filtered[cdp_features + cdp_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = cdp_data_filtered[cdp_features]\n",
    "    y = cdp_data_filtered[cdp_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the MLP model\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(100, 100), activation='relu', solver='adam', random_state=42)\n",
    "    mlp_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"cdp_mlp_model.pkl\")\n",
    "    joblib.dump(mlp_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/cdp_mlp_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CDP - MLP MSE:\", mse_mlp)\n",
    "    print(\"CDP - MLP MAE:\", mae_mlp)\n",
    "    print(\"CDP - MLP R²:\", r2_mlp)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_mlp_df = pd.DataFrame(y_pred_mlp, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[cdp_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_mlp_df[cdp_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CDP - {cdp_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{cdp_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/cdp_{cdp_target[0]}_prediction.html\")\n",
    "\n",
    "    # Permutation Feature Importance\n",
    "    perm_importance = permutation_importance(mlp_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "    # Plot Permutation Importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_test.columns[sorted_idx],\n",
    "        'Importance': perm_importance.importances_mean[sorted_idx]\n",
    "    })\n",
    "\n",
    "    fig_importance = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "                            title='CDP - Feature Importance')\n",
    "    fig_importance.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_importance.write_image(f\"{save_path}/feature/cdp_feature_importance.png\")\n",
    "\n",
    "    # Correlation coefficients\n",
    "    corr_matrix = cdp_data_filtered[cdp_features + cdp_target].corr()\n",
    "    corr_target = corr_matrix[cdp_target[0]].drop(cdp_target[0])  # Drop the target's correlation with itself\n",
    "\n",
    "    fig_corr_coef = px.bar(x=corr_target.values, y=corr_target.index, orientation='h',\n",
    "                           title=f'CDP - Feature Correlation with {cdp_target[0]}')\n",
    "    fig_corr_coef.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/correlation/\", exist_ok=True)\n",
    "    fig_corr_coef.write_image(f\"{save_path}/correlation/cdp_feature_correlation.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/cdp_power_model_mlp\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate MLP model for the CDP power prediction\n",
    "train_and_evaluate_mlp_cdp(chiller_data, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Function to train and evaluate Linear Regression model for CT\n",
    "def train_and_evaluate_linear_regression_ct(chiller_data, save_path):\n",
    "\n",
    "    # Define feature mapping for clarity in plots\n",
    "    feature_mapping = {\n",
    "        'plant_cooling_rate': 'PCR',\n",
    "        'condenser_water_loop_flow_rate': 'PCDWF',\n",
    "        'outdoor_weather_station_wetbulb_temperature': 'WBT',\n",
    "        'outdoor_weather_station_drybulb_temperature': 'DBT',\n",
    "        'outdoor_weather_station_relative_humidity': 'RH',\n",
    "        'outdoor_weather_station_wetbulb_temperature_squared': 'WBT²',\n",
    "        'outdoor_weather_station_wetbulb_temperature_cubed': 'WBT³',\n",
    "        'outdoor_weather_station_wetbulb_temperature_fourth': 'WBT4'\n",
    "    }\n",
    "    \n",
    "    ct_features = list(feature_mapping.keys())\n",
    "\n",
    "\n",
    "    # Add new features to the dataset\n",
    "    chiller_data['outdoor_weather_station_wetbulb_temperature_squared'] = chiller_data['outdoor_weather_station_wetbulb_temperature'] ** 2\n",
    "    chiller_data['outdoor_weather_station_wetbulb_temperature_cubed'] = chiller_data['outdoor_weather_station_wetbulb_temperature'] ** 3\n",
    "    chiller_data['outdoor_weather_station_wetbulb_temperature_fourth'] = chiller_data['outdoor_weather_station_wetbulb_temperature'] ** 4\n",
    "\n",
    "    ct_target = ['plant_power_all_cts']\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_cts' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_cts'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    ct_data_filtered = chiller_data_filtered[(chiller_data_filtered[ct_features + ct_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = ct_data_filtered[ct_features]\n",
    "    y = ct_data_filtered[ct_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"ct_linear_regression_model.pkl\")\n",
    "    joblib.dump(lr_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/ct_linear_regression_scaler.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "    r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CT - Linear Regression MSE:\", mse_lr)\n",
    "    print(\"CT - Linear Regression MAE:\", mae_lr)\n",
    "    print(\"CT - Linear Regression R²:\", r2_lr)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_lr_df = pd.DataFrame(y_pred_lr, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[ct_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_lr_df[ct_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CT - {ct_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{ct_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/ct_{ct_target[0]}_prediction.html\")\n",
    "\n",
    "    # Permutation Feature Importance\n",
    "    perm_importance = permutation_importance(lr_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "    # Plot Permutation Importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': [feature_mapping[feature] for feature in X.columns[sorted_idx]],\n",
    "        'Importance': perm_importance.importances_mean[sorted_idx]\n",
    "    })\n",
    "\n",
    "    fig_importance = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "                            title='CT - Feature Importance')\n",
    "    fig_importance.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_importance.write_image(f\"{save_path}/feature/ct_feature_importance.png\")\n",
    "\n",
    "    # Correlation Coefficient Plot\n",
    "    corr_coef = X.corrwith(y.iloc[:, 0])\n",
    "    corr_df = pd.DataFrame({\n",
    "        'Feature': [feature_mapping[feature] for feature in X.columns],\n",
    "        'Correlation Coefficient': corr_coef.values\n",
    "    })\n",
    "    corr_df = corr_df.sort_values(by='Correlation Coefficient', ascending=True)\n",
    "    fig_corr = px.bar(corr_df, x='Correlation Coefficient', y='Feature', orientation='h',\n",
    "                      title='CT - Correlation Coefficients')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    fig_corr.write_image(f\"{save_path}/feature/ct_correlation_coefficients.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/ct_power_model_lr\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Train and evaluate Linear Regression model for the CT power prediction\n",
    "train_and_evaluate_linear_regression_ct(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to train and evaluate Random Forest model for CT\n",
    "def train_and_evaluate_random_forest_ct(chiller_data, save_path):\n",
    "\n",
    "    ct_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'condenser_water_loop_flow_rate',\n",
    "        'outdoor_weather_station_wetbulb_temperature',\n",
    "        'outdoor_weather_station_drybulb_temperature',\n",
    "        'outdoor_weather_station_relative_humidity'\n",
    "    ]\n",
    "    \n",
    "    ct_target = ['plant_power_all_cts']\n",
    "\n",
    "    feature_mapping = {\n",
    "        'plant_cooling_rate': 'PCR',\n",
    "        'condenser_water_loop_flow_rate': 'PCDWF',\n",
    "        'outdoor_weather_station_wetbulb_temperature': 'WBT',\n",
    "        'outdoor_weather_station_drybulb_temperature': 'DBT',\n",
    "        'outdoor_weather_station_relative_humidity': 'RH',\n",
    "    }\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_cts' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_cts'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    ct_data_filtered = chiller_data_filtered[(chiller_data_filtered[ct_features + ct_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = ct_data_filtered[ct_features]\n",
    "    y = ct_data_filtered[ct_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"ct_random_forest_model.pkl\")\n",
    "    joblib.dump(rf_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/ct_random_forest_scaler.pkl\")\n",
    "    # Predict\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CT - Random Forest MSE:\", mse_rf)\n",
    "    print(\"CT - Random Forest MAE:\", mae_rf)\n",
    "    print(\"CT - Random Forest R²:\", r2_rf)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_rf_df = pd.DataFrame(y_pred_rf, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[ct_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_rf_df[ct_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CT - {ct_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{ct_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/ct_{ct_target[0]}_prediction.html\")\n",
    "\n",
    "    # Feature Importances\n",
    "    feature_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
    "    feature_importances = feature_importances.sort_values(ascending=True)  # Ascending order\n",
    "\n",
    "    feature_importances.index = feature_importances.index.map(feature_mapping)\n",
    "\n",
    "    fig_corr = px.bar(x=feature_importances.values, y=feature_importances.index, orientation='h',\n",
    "                      title=f'CT - Feature Importances')\n",
    "    fig_corr.update_layout(\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature'\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/chp_feature_importance.png\")\n",
    "\n",
    "    # Correlation Coefficients\n",
    "    correlation_matrix = chiller_data[ct_features + ct_target].corr()\n",
    "    correlation_with_target = correlation_matrix[ct_target[0]].drop(ct_target[0]).sort_values()\n",
    "\n",
    "    # Plot Correlation Coefficients\n",
    "    fig_corr = go.Figure(go.Bar(\n",
    "        x=correlation_with_target.values,\n",
    "        y=correlation_with_target.index,\n",
    "        orientation='h'\n",
    "    ))\n",
    "\n",
    "    fig_corr.update_layout(\n",
    "        title='CT - Correlation Coefficients',\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature',\n",
    "        yaxis=dict(tickmode='linear')\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/ct_correlation_coefficients.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/ct_power_model_rf\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Assuming chiller_data is already loaded in your environment\n",
    "# Train and evaluate Random Forest model for the CT power prediction\n",
    "train_and_evaluate_random_forest_ct(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to train and evaluate MLP model for CT\n",
    "def train_and_evaluate_mlp_ct(chiller_data, save_path):\n",
    "\n",
    "    ct_features = [\n",
    "        'plant_cooling_rate',\n",
    "        'condenser_water_loop_flow_rate',\n",
    "        'outdoor_weather_station_wetbulb_temperature',\n",
    "        'outdoor_weather_station_drybulb_temperature',\n",
    "        'outdoor_weather_station_relative_humidity'\n",
    "    ]\n",
    "\n",
    "    ct_target = ['plant_power_all_cts']\n",
    "\n",
    "    # Filter data to drop rows where 'plant_number_of_running_cts' is 0\n",
    "    chiller_data_filtered = chiller_data[chiller_data['plant_number_of_running_cts'] != 0]\n",
    "\n",
    "    # Filter data to drop rows where any feature or target is 0\n",
    "    ct_data_filtered = chiller_data_filtered[(chiller_data_filtered[ct_features + ct_target] != 0).all(axis=1)].copy()\n",
    "\n",
    "    X = ct_data_filtered[ct_features]\n",
    "    y = ct_data_filtered[ct_target]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)  # Convert back to DataFrame with index\n",
    "\n",
    "    train_size = int(0.6 * len(X_scaled_df))\n",
    "    X_train, y_train = X_scaled_df[:train_size], y[:train_size]\n",
    "    X_test, y_test = X_scaled_df[train_size:], y[train_size:]\n",
    "\n",
    "    # Train the MLP model\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(100, 100), activation='relu', random_state=42, max_iter=500)\n",
    "    mlp_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "    model_save_path = os.path.join(save_path, \"models\", \"ct_mlp_model.pkl\")\n",
    "    joblib.dump(mlp_model, model_save_path)\n",
    "    os.makedirs(f\"{save_path}/scalers/\", exist_ok=True)\n",
    "    joblib.dump(scaler, f\"{save_path}/scalers/ct_mlp_scaler.pkl\")\n",
    "    # Predict\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "    # Performance Metrics\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"CT - MLP MSE:\", mse_mlp)\n",
    "    print(\"CT - MLP MAE:\", mae_mlp)\n",
    "    print(\"CT - MLP R²:\", r2_mlp)\n",
    "\n",
    "    # Plotting\n",
    "    y_pred_mlp_df = pd.DataFrame(y_pred_mlp, index=y_test.index, columns=y_test.columns)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_test[ct_target[0]], mode='lines', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x=X_test.index, y=y_pred_mlp_df[ct_target[0]], mode='lines', name='Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=f'CT - {ct_target[0]} Prediction',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f'{ct_target[0]}',\n",
    "        legend_title='Legend'\n",
    "    )\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/plot/\", exist_ok=True)\n",
    "\n",
    "    # Save plot as HTML\n",
    "    fig.write_html(f\"{save_path}/plot/ct_{ct_target[0]}_prediction.html\")\n",
    "\n",
    "    # Correlation Coefficients\n",
    "    correlation_matrix = chiller_data[ct_features + ct_target].corr()\n",
    "    correlation_with_target = correlation_matrix[ct_target[0]].drop(ct_target[0]).sort_values()\n",
    "\n",
    "    # Plot Correlation Coefficients\n",
    "    fig_corr = go.Figure(go.Bar(\n",
    "        x=correlation_with_target.values,\n",
    "        y=correlation_with_target.index,\n",
    "        orientation='h'\n",
    "    ))\n",
    "\n",
    "    fig_corr.update_layout(\n",
    "        title='CT - Correlation Coefficients',\n",
    "        xaxis_title='Correlation Coefficient',\n",
    "        yaxis_title='Feature',\n",
    "        yaxis=dict(tickmode='linear')\n",
    "    )\n",
    "\n",
    "    # Ensure the directory exists for saving plots\n",
    "    os.makedirs(f\"{save_path}/feature/\", exist_ok=True)\n",
    "    fig_corr.write_image(f\"{save_path}/feature/ct_correlation_coefficients.png\")\n",
    "\n",
    "# Set your desired save path\n",
    "save_path = \"../visualizations/ct_power_model_mlp\"\n",
    "\n",
    "# Ensure the directory exists for saving models\n",
    "os.makedirs(f\"{save_path}/models/\", exist_ok=True)\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming chiller_data is already loaded in your environment\n",
    "\n",
    "# Train and evaluate MLP model for the CT power prediction\n",
    "train_and_evaluate_mlp_ct(chiller_data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio.tools as tls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your Chart Studio credentials\n",
    "username = 'puminjirapu'\n",
    "api_key = 'qyvau6rmqLRuYm29W5gd'\n",
    "\n",
    "# Set credentials\n",
    "tls.set_credentials_file(username=username, api_key=api_key)\n",
    "\n",
    "# Load the saved Plotly HTML file\n",
    "fig = pio.read_html(\"../visualizations/ct_power_model_lr/plot/ct_plant_power_all_cts_prediction.html\")\n",
    "# Upload figure to Chart Studio\n",
    "py.plot(fig, filename='uploaded-plot', auto_open=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import itertools\n",
    "import joblib\n",
    "\n",
    "# Constants\n",
    "N_CHILLERS = 5\n",
    "MIN_CHW_FLOW = 400  # GPM\n",
    "MAX_CHW_FLOW = 2500  # GPM\n",
    "MIN_CDW_FLOW = 500  # GPM\n",
    "MAX_CDW_FLOW = 3000  # GPM\n",
    "MAX_CHR_TEMP = 59  # °F\n",
    "CHILLER_CAPACITY = 800  # Tons\n",
    "\n",
    "# Load data\n",
    "data = pd.read_parquet('chiller_data_pre.parquet')\n",
    "data = data[-100:]\n",
    "\n",
    "def chiller_power(chiller_mode, chiller_id, chw_setpoint, chw_flow, cdw_flow, cooling_rate):\n",
    "    # Check for zero input features\n",
    "    if any(x == 0 for x in [chiller_mode, chw_setpoint, chw_flow, cdw_flow, cooling_rate]):\n",
    "        return 0\n",
    "    \n",
    "    if chiller_id == 1 or chiller_id == 2:\n",
    "        model_path = f\"../visualizations/power_model_rf/models/chiller_{chiller_id}_random_forest_model.pkl\"\n",
    "    else:\n",
    "        model_path = f\"../visualizations/power_model_mlp/models/chiller_{chiller_id}_mlp_model.pkl\"\n",
    "    model = joblib.load(model_path)\n",
    "    # Prepare input data as a DataFrame\n",
    "    input_data = {\n",
    "        f'chiller_{chiller_id}_evap_leaving_water_temperature': [chw_setpoint],\n",
    "        f'chiller_{chiller_id}_evap_water_flow_rate': [chw_flow],\n",
    "        f'chiller_{chiller_id}_cond_water_flow_rate': [cdw_flow],\n",
    "        f'chiller_{chiller_id}_cooling_rate': [cooling_rate]\n",
    "    }\n",
    "\n",
    "    # Convert input data to DataFrame\n",
    "    input_data = pd.DataFrame(input_data)\n",
    "\n",
    "    # input_data[f'chiller_{chiller_id}_evap_leaving_water_temperature_squared'] = input_data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] ** 2\n",
    "    # input_data[f'chiller_{chiller_id}_evap_leaving_water_temperature_cond_flow'] = input_data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] * input_data[f'chiller_{chiller_id}_cond_water_flow_rate']\n",
    "    # input_data[f'chiller_{chiller_id}_cond_water_flow_rate_squared'] = input_data[f'chiller_{chiller_id}_cond_water_flow_rate'] ** 2\n",
    "    # input_data[f'chiller_{chiller_id}_evap_water_flow_rate_squared'] = input_data[f'chiller_{chiller_id}_evap_water_flow_rate'] ** 2\n",
    "    # input_data[f'chiller_{chiller_id}_evap_leaving_water_temperature_evap_water_flow_rate'] = input_data[f'chiller_{chiller_id}_evap_leaving_water_temperature'] * input_data[f'chiller_{chiller_id}_evap_water_flow_rate']\n",
    "\n",
    "    # Scale input features if necessary (assuming StandardScaler was used during training)\n",
    "    if chiller_id == 1 or chiller_id == 2:\n",
    "        scaler = joblib.load(f\"../visualizations/power_model_rf/scalers/chiller_{chiller_id}_random_forest_scaler.pkl\")  # Use the same scaler as during training\n",
    "    else:\n",
    "        scaler = joblib.load(f\"../visualizations/power_model_mlp/scalers/chiller_{chiller_id}_mlp_scaler.pkl\")\n",
    "    input_scaled = scaler.transform(input_data)  # fit_transform for new data\n",
    "    input_scaled_df = pd.DataFrame(input_scaled, columns=input_data.columns)\n",
    "\n",
    "    # Predict chiller power\n",
    "    chiller_power_prediction = model.predict(input_scaled_df)\n",
    "\n",
    "    return chiller_power_prediction[0]\n",
    "\n",
    "def chp_power(chiller_modes, chw_flows, cooling_load):\n",
    "    total_chw_flow = sum([flow * mode for flow, mode in zip(chw_flows, chiller_modes)])\n",
    "    if cooling_load == 0 or total_chw_flow:\n",
    "        return 0\n",
    "    model = joblib.load('../visualizations/chp_power_model_lr/models/chp_linear_regression_model.pkl')\n",
    "    # Prepare input data as a DataFrame\n",
    "    input_data = {\n",
    "        'plant_cooling_rate': [cooling_load],\n",
    "        'chilled_water_loop_flow_rate': [total_chw_flow]\n",
    "    }\n",
    "\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "\n",
    "    # Add new features to the input data\n",
    "    input_df['chilled_water_loop_flow_rate_squared'] = input_df['chilled_water_loop_flow_rate'] ** 2\n",
    "    input_df['chilled_water_loop_flow_rate_cubed'] = input_df['chilled_water_loop_flow_rate'] ** 3\n",
    "\n",
    "    # Scale input features if necessary (assuming StandardScaler was used during training)\n",
    "    scaler = joblib.load(f\"../visualizations/chp_power_model_lr/scalers/chp_linear_regression_scaler.pkl\")  # Use the same scaler as during training\n",
    "    input_scaled = scaler.transform(input_df)  # fit_transform for new data\n",
    "    input_scaled_df = pd.DataFrame(input_scaled, columns=input_df.columns)\n",
    "\n",
    "    # Predict CHP power\n",
    "    chp_power_prediction = model.predict(input_scaled_df)\n",
    "\n",
    "    return chp_power_prediction[0]\n",
    "\n",
    "def cdp_power(chiller_modes, cdw_flows, cooling_load):\n",
    "    total_cdw_flow = sum([flow * mode for flow, mode in zip(cdw_flows, chiller_modes)])\n",
    "    if cooling_load == 0 or total_cdw_flow==0:\n",
    "        return 0\n",
    "    model = joblib.load('../visualizations/cdp_power_model_lr/models/cdp_linear_regression_model.pkl')\n",
    "    # Prepare input data as a DataFrame\n",
    "    input_data = {\n",
    "        'plant_cooling_rate': [cooling_load],\n",
    "        'condenser_water_loop_flow_rate': [total_cdw_flow]\n",
    "    }\n",
    "\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "\n",
    "    # Add new features to the input data\n",
    "    input_df['condenser_water_loop_flow_rate_squared'] = input_df['condenser_water_loop_flow_rate'] ** 2\n",
    "    input_df['condenser_water_loop_flow_rate_cubed'] = input_df['condenser_water_loop_flow_rate'] ** 3\n",
    "\n",
    "    # Scale input features if necessary (assuming StandardScaler was used during training)\n",
    "    scaler = joblib.load(f\"../visualizations/cdp_power_model_lr/scalers/cdp_linear_regression_scaler.pkl\")  # Use the same scaler as during training\n",
    "    input_scaled = scaler.transform(input_df)  # fit_transform for new data\n",
    "    input_scaled_df = pd.DataFrame(input_scaled, columns=input_df.columns)\n",
    "\n",
    "    # Predict CDP power\n",
    "    cdp_power_prediction = model.predict(input_scaled_df)\n",
    "\n",
    "    return cdp_power_prediction[0]\n",
    "\n",
    "def ct_power(chiller_modes, cdw_flows, cooling_load, state):\n",
    "    total_cdw_flow = sum([flow * mode for flow, mode in zip(cdw_flows, chiller_modes)])\n",
    "    if cooling_load == 0 or total_cdw_flow==0:\n",
    "        return 0\n",
    "    model = joblib.load('../visualizations/ct_power_model_lr/models/ct_linear_regression_model.pkl')\n",
    "    # Prepare input data as a DataFrame\n",
    "    input_data = {\n",
    "        'plant_cooling_rate': [cooling_load],\n",
    "        'condenser_water_loop_flow_rate': [total_cdw_flow],\n",
    "        'outdoor_weather_station_wetbulb_temperature': [state['outdoor_weather_station_wetbulb_temperature']],\n",
    "        'outdoor_weather_station_drybulb_temperature': [state['outdoor_weather_station_drybulb_temperature']],\n",
    "        'outdoor_weather_station_relative_humidity': [state['outdoor_weather_station_relative_humidity']]\n",
    "    }\n",
    "\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "\n",
    "    # Add new features to the input data\n",
    "    input_df['outdoor_weather_station_wetbulb_temperature_squared'] = input_df['outdoor_weather_station_wetbulb_temperature'] ** 2\n",
    "    input_df['outdoor_weather_station_wetbulb_temperature_cubed'] = input_df['outdoor_weather_station_wetbulb_temperature'] ** 3\n",
    "    input_df['outdoor_weather_station_wetbulb_temperature_fourth'] = input_df['outdoor_weather_station_wetbulb_temperature'] ** 4\n",
    "\n",
    "    # Scale input features if necessary (assuming StandardScaler was used during training)\n",
    "    scaler = joblib.load(f\"../visualizations/ct_power_model_lr/scalers/ct_linear_regression_scaler.pkl\")  # Use the same scaler as during training\n",
    "    input_scaled = scaler.transform(input_df)  # fit_transform for new data\n",
    "    input_scaled_df = pd.DataFrame(input_scaled, columns=input_df.columns)\n",
    "\n",
    "    # Predict CT power\n",
    "    ct_power_prediction = model.predict(input_scaled_df)\n",
    "\n",
    "    return ct_power_prediction[0]\n",
    "\n",
    "def chw_temp_out(state, chiller_modes, chw_setpoints, cooling_load, chw_flows):\n",
    "    total_chw_flow = sum([flow * mode for flow, mode in zip(chw_flows, chiller_modes)])\n",
    "    actual_chs = sum([flow * chw_setpoint for flow, chw_setpoint in zip(chw_flows, chw_setpoints)]) / total_chw_flow \\\n",
    "        if total_chw_flow > 0 else state['plant_target_chw_setpoint']\n",
    "    chr_temp = actual_chs + (24 * cooling_load / total_chw_flow if total_chw_flow != 0 else 0)\n",
    "    return chr_temp\n",
    "\n",
    "def chiller_cooling_rate(chiller_mode, chw_flow, chw_setpoint, chr_temp):\n",
    "    return chw_flow * (chr_temp - chw_setpoint) / 24\n",
    "\n",
    "# Chiller change tracking\n",
    "class ChillerChangeTracker:\n",
    "    def __init__(self, n_chillers):\n",
    "        self.n_chillers = n_chillers\n",
    "        self.changes = np.zeros(n_chillers, dtype=int)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.changes.fill(0)\n",
    "    \n",
    "    def can_change(self, chiller_index):\n",
    "        return self.changes[chiller_index] < 1\n",
    "    \n",
    "    def record_change(self, chiller_index):\n",
    "        self.changes[chiller_index] += 1\n",
    "\n",
    "def system_model(state, inputs, cooling_load):\n",
    "    n_inputs = len(inputs)\n",
    "    n_chillers = N_CHILLERS\n",
    "    \n",
    "    chiller_modes = [int(round(x)) for x in inputs[:n_chillers]]\n",
    "    chw_setpoints = inputs[n_chillers:2*n_chillers]\n",
    "    chw_flows = inputs[2*n_chillers:3*n_chillers]\n",
    "    cdw_flows = inputs[3*n_chillers:] if len(inputs) > 3*n_chillers else [0] * n_chillers\n",
    "\n",
    "    # Ensure non-zero values for active chillers and zero for inactive ones\n",
    "    for i in range(n_chillers):\n",
    "        if chiller_modes[i] == 0:\n",
    "            chw_setpoints[i] = 0\n",
    "            chw_flows[i] = 0\n",
    "            cdw_flows[i] = 0\n",
    "        else:\n",
    "            chw_setpoints[i] = max(40, min(50, chw_setpoints[i]))\n",
    "            chw_flows[i] = max(MIN_CHW_FLOW, chw_flows[i])\n",
    "            cdw_flows[i] = max(MIN_CDW_FLOW, cdw_flows[i])\n",
    "\n",
    "    print(f\"Debug: chiller_modes = {chiller_modes}\")\n",
    "    print(f\"Debug: chw_setpoints = {chw_setpoints}\")\n",
    "    print(f\"Debug: chw_flows = {chw_flows}\")\n",
    "    print(f\"Debug: cdw_flows = {cdw_flows}\")\n",
    "\n",
    "    chr_temp = chw_temp_out(state, chiller_modes, chw_setpoints, cooling_load, chw_flows)\n",
    "    clr_chillers = [chiller_cooling_rate(chiller_modes[i], chw_flows[i], chw_setpoints[i], chr_temp) for i in range(n_chillers)]\n",
    "\n",
    "    total_power = 0\n",
    "    for i in range(n_chillers):\n",
    "        if chiller_modes[i]:\n",
    "            total_power += chiller_power(chiller_modes[i], i+1, chw_setpoints[i], chw_flows[i], cdw_flows[i], clr_chillers[i])\n",
    "    \n",
    "    total_power += chp_power(chiller_modes, chw_flows, cooling_load)\n",
    "    total_power += cdp_power(chiller_modes, cdw_flows, cooling_load)\n",
    "    total_power += ct_power(chiller_modes, cdw_flows, cooling_load, state)\n",
    "    print(f\"Debug: total_cal power = {total_power}\")\n",
    "    return state, total_power\n",
    "\n",
    "def objective(inputs, current_state, cooling_load):\n",
    "    _, power = system_model(current_state, inputs, cooling_load)\n",
    "    return power\n",
    "\n",
    "def constraints(inputs, current_state, cooling_load, prev_chiller_modes, chiller_tracker):\n",
    "    chiller_modes = inputs[:N_CHILLERS]\n",
    "    chw_setpoints = inputs[N_CHILLERS:2*N_CHILLERS]\n",
    "    chw_flows = inputs[2*N_CHILLERS:3*N_CHILLERS]\n",
    "    cdw_flows = inputs[3*N_CHILLERS:]\n",
    "    chr_temp = chw_temp_out(current_state, chiller_modes, chw_setpoints, cooling_load, chw_flows)\n",
    "    constraints = []\n",
    "    \n",
    "    # 1. Sufficient cooling capacity\n",
    "    total_capacity = sum(chiller_modes) * CHILLER_CAPACITY\n",
    "    constraints.append(total_capacity - cooling_load)\n",
    "    \n",
    "    # 1.a Sufficient cooling capacity each chiller\n",
    "    clr_chillers = [chiller_cooling_rate(chiller_modes[i], chw_flows[i], chw_setpoints[i], chr_temp) for i in range(N_CHILLERS)]\n",
    "    for i in range(N_CHILLERS):\n",
    "        constraints.append(CHILLER_CAPACITY - clr_chillers[i])\n",
    "    \n",
    "    # 2. Chiller on/off limit (not more than once per day)\n",
    "    for i in range(N_CHILLERS):\n",
    "        if chiller_modes[i] != prev_chiller_modes[i] and not chiller_tracker.can_change(i):\n",
    "            constraints.append(-1)  # This will make the solution invalid\n",
    "        else:\n",
    "            constraints.append(0)\n",
    "    \n",
    "    # 3. Flow rate limits\n",
    "    for i in range(N_CHILLERS):\n",
    "        if chiller_modes[i] != 0 and chw_flows[i] != 0:\n",
    "            constraints.append(chw_flows[i] - MIN_CHW_FLOW)\n",
    "            constraints.append(MAX_CHW_FLOW - chw_flows[i])\n",
    "        elif chiller_modes[i] == 0 and chw_flows[i] == 0:\n",
    "            constraints.append(0)\n",
    "            constraints.append(0)\n",
    "        else:\n",
    "            constraints.append(-1)\n",
    "            constraints.append(-1)\n",
    "\n",
    "    for i in range(N_CHILLERS):\n",
    "        if chiller_modes[i] != 0 and cdw_flows[i] != 0:\n",
    "            constraints.append(cdw_flows[i] - MIN_CDW_FLOW)\n",
    "            constraints.append(MAX_CDW_FLOW - cdw_flows[i])\n",
    "        elif chiller_modes[i] == 0 and cdw_flows[i] == 0:\n",
    "            constraints.append(0)\n",
    "            constraints.append(0)\n",
    "        else:\n",
    "            constraints.append(-1)\n",
    "            constraints.append(-1)\n",
    "    \n",
    "    #4. Returning chilled water temperature limit\n",
    "    constraints.append(MAX_CHR_TEMP - chr_temp)\n",
    "    \n",
    "    #5. Combined chilled water supply temperature\n",
    "    target_chs = current_state['plant_target_chw_setpoint']\n",
    "    total_chw_flow = sum([flow * mode for flow, mode in zip(chw_flows, chiller_modes)])\n",
    "    actual_chs = sum([flow * chw_setpoint for flow, chw_setpoint in zip(chw_flows, chw_setpoints)]) / total_chw_flow \\\n",
    "        if total_chw_flow > 0 else target_chs\n",
    "    constraints.append(0.1 - abs(actual_chs - target_chs))\n",
    "    \n",
    "    return constraints\n",
    "\n",
    "def get_min_chillers_required(cooling_load):\n",
    "    return max(1, math.ceil(cooling_load / CHILLER_CAPACITY))\n",
    "\n",
    "def can_use_previous_modes(prev_modes, min_chillers_required):\n",
    "    active_chillers = sum(prev_modes)\n",
    "    return min_chillers_required <= active_chillers <= min_chillers_required + 1\n",
    "\n",
    "def get_valid_chiller_combinations(min_chillers_required, prev_modes, chiller_tracker):\n",
    "    valid_combinations = []\n",
    "    for combo in itertools.combinations(range(N_CHILLERS), min_chillers_required):\n",
    "        modes = [1 if i in combo else 0 for i in range(N_CHILLERS)]\n",
    "        if all(modes[i] == prev_modes[i] or chiller_tracker.can_change(i) for i in range(N_CHILLERS)):\n",
    "            valid_combinations.append(modes)\n",
    "    return valid_combinations\n",
    "\n",
    "def check_constraints(inputs, current_state, cooling_load, prev_chiller_modes, chiller_tracker, tolerance=1e-6):\n",
    "    constraints_values = constraints(inputs, current_state, cooling_load, prev_chiller_modes, chiller_tracker)\n",
    "    violated_constraints = []\n",
    "    for i, c in enumerate(constraints_values):\n",
    "        if c < -tolerance:\n",
    "            violated_constraints.append((i, c))\n",
    "    return violated_constraints\n",
    "\n",
    "def optimize_continuous_vars(discrete_vars, cooling_load, current_state, prev_chiller_modes, chiller_tracker):\n",
    "    def objective_wrapper(x):\n",
    "        full_input = create_full_input(discrete_vars, x)\n",
    "        return objective(full_input, current_state, cooling_load)\n",
    "\n",
    "    def constraint_wrapper(x):\n",
    "        full_input = create_full_input(discrete_vars, x)\n",
    "        return constraints(full_input, current_state, cooling_load, prev_chiller_modes, chiller_tracker)\n",
    "\n",
    "    def create_full_input(discrete_vars, x):\n",
    "        chw_setpoints = []\n",
    "        chw_flows = []\n",
    "        cdw_flows = []\n",
    "        x_index = 0\n",
    "        for i in range(N_CHILLERS):\n",
    "            if discrete_vars[i] == 1:\n",
    "                chw_setpoints.append(x[x_index])\n",
    "                chw_flows.append(x[x_index + 1])\n",
    "                cdw_flows.append(x[x_index + 2])\n",
    "                x_index += 3\n",
    "            else:\n",
    "                chw_setpoints.append(0)\n",
    "                chw_flows.append(0)\n",
    "                cdw_flows.append(0)\n",
    "        return discrete_vars + chw_setpoints + chw_flows + cdw_flows\n",
    "\n",
    "    bounds = []\n",
    "    initial_guess = []\n",
    "    for i in range(N_CHILLERS):\n",
    "        if discrete_vars[i] == 1:\n",
    "            chw_setpoint = random.uniform(40, 50)\n",
    "            chw_flow = random.uniform(MIN_CHW_FLOW, MAX_CHW_FLOW)\n",
    "            cdw_flow = random.uniform(MIN_CDW_FLOW, MAX_CDW_FLOW)\n",
    "            \n",
    "            initial_guess.extend([chw_setpoint, chw_flow, cdw_flow])\n",
    "            bounds.extend([(40, 50), (MIN_CHW_FLOW, MAX_CHW_FLOW), (MIN_CDW_FLOW, MAX_CDW_FLOW)])\n",
    "\n",
    "    result = minimize(\n",
    "        objective_wrapper,\n",
    "        initial_guess,\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints={'type': 'ineq', 'fun': constraint_wrapper},\n",
    "        options={'maxiter': 100, 'ftol': 1e-6}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        best_solution = result.x\n",
    "        best_power = result.fun\n",
    "    else:\n",
    "        print(\"Optimization failed. Using initial guess.\")\n",
    "        best_solution = initial_guess\n",
    "        best_power = objective_wrapper(initial_guess)\n",
    "\n",
    "    chw_setpoints = [0] * N_CHILLERS\n",
    "    chw_flows = [0] * N_CHILLERS\n",
    "    cdw_flows = [0] * N_CHILLERS\n",
    "\n",
    "    var_index = 0\n",
    "    for i in range(N_CHILLERS):\n",
    "        if discrete_vars[i] == 1:\n",
    "            chw_setpoints[i] = best_solution[var_index]\n",
    "            chw_flows[i] = best_solution[var_index + 1]\n",
    "            cdw_flows[i] = best_solution[var_index + 2]\n",
    "            var_index += 3\n",
    "\n",
    "    full_output = chw_setpoints + chw_flows + cdw_flows\n",
    "\n",
    "    print(f\"Best solution found - Power: {best_power}\")\n",
    "    print(\"Debug: Best solution chiller modes =\", discrete_vars)\n",
    "    print(\"Debug: Best solution chw_setpoints =\", chw_setpoints)\n",
    "    print(\"Debug: Best solution chw_flows =\", chw_flows)\n",
    "    print(\"Debug: Best solution cdw_flows =\", cdw_flows)\n",
    "    return full_output, best_power\n",
    "\n",
    "def mpc_control(initial_state):\n",
    "    current_state = initial_state.copy()\n",
    "    optimal_trajectory = []\n",
    "    prev_chiller_modes = [0] * N_CHILLERS\n",
    "    chiller_tracker = ChillerChangeTracker(N_CHILLERS)\n",
    "    \n",
    "    for t in range(len(data)):\n",
    "        cooling_load = data.iloc[t]['plant_cooling_rate']\n",
    "        current_state['outdoor_weather_station_wetbulb_temperature'] = data.iloc[t]['outdoor_weather_station_wetbulb_temperature']\n",
    "        current_state['outdoor_weather_station_drybulb_temperature'] = data.iloc[t]['outdoor_weather_station_drybulb_temperature']\n",
    "        current_state['outdoor_weather_station_relative_humidity'] = data.iloc[t]['outdoor_weather_station_relative_humidity']\n",
    "        current_state['plant_target_chw_setpoint'] = data.iloc[t]['plant_target_chw_setpoint']\n",
    "        current_state['new_day'] = data.iloc[t]['new_day']\n",
    "        \n",
    "        if current_state['new_day'] == 1:\n",
    "            chiller_tracker.reset()\n",
    "\n",
    "        print(f\"\\nTime step: {t}\")\n",
    "        print(f\"Cooling load: {cooling_load}\")\n",
    "        print(f\"Previous chiller modes: {prev_chiller_modes}\")\n",
    "        print(f\"Current state: {current_state}\")\n",
    "\n",
    "        min_chillers_required = get_min_chillers_required(cooling_load)\n",
    "\n",
    "        if can_use_previous_modes(prev_chiller_modes, min_chillers_required):\n",
    "            discrete_vars = prev_chiller_modes.copy()\n",
    "            \n",
    "            # Check if we need to turn on or off chillers\n",
    "            active_chillers = sum(discrete_vars)\n",
    "            if active_chillers > min_chillers_required:\n",
    "                # Consider turning off excess chillers\n",
    "                while sum(discrete_vars) > min_chillers_required:\n",
    "                    chiller_to_turn_off = random.choice([i for i in range(N_CHILLERS) if discrete_vars[i] == 1])\n",
    "                    if chiller_tracker.can_change(chiller_to_turn_off):\n",
    "                        discrete_vars[chiller_to_turn_off] = 0\n",
    "                    else:\n",
    "                        break\n",
    "            elif active_chillers < min_chillers_required:\n",
    "                # Consider turning on additional chillers\n",
    "                while sum(discrete_vars) < min_chillers_required:\n",
    "                    chiller_to_turn_on = random.choice([i for i in range(N_CHILLERS) if discrete_vars[i] == 0])\n",
    "                    if chiller_tracker.can_change(chiller_to_turn_on):\n",
    "                        discrete_vars[chiller_to_turn_on] = 1\n",
    "                    else:\n",
    "                        break\n",
    "            print(\"Using modified previous chiller modes\")\n",
    "        else:\n",
    "            valid_combinations = get_valid_chiller_combinations(min_chillers_required, prev_chiller_modes, chiller_tracker)\n",
    "            if not valid_combinations:\n",
    "                print(\"No valid combinations found. Using random combination.\")\n",
    "                discrete_vars = [0] * N_CHILLERS\n",
    "                active_indices = random.sample(range(N_CHILLERS), min_chillers_required)\n",
    "                for idx in active_indices:\n",
    "                    discrete_vars[idx] = 1\n",
    "            else:\n",
    "                best_combination = None\n",
    "                best_power = float('inf')\n",
    "                for combo in valid_combinations:\n",
    "                    continuous_vars, power = optimize_continuous_vars(combo, cooling_load, current_state, prev_chiller_modes, chiller_tracker)\n",
    "                    full_input = combo + continuous_vars\n",
    "                    # power = objective(full_input, current_state, cooling_load)\n",
    "                    print(f\"Testing combination {combo} - Power: {power}\")\n",
    "                    if power < best_power:\n",
    "                        best_power = power\n",
    "                        best_combination = combo\n",
    "                discrete_vars = best_combination\n",
    "            print(f\"Selected discrete vars: {discrete_vars}\")\n",
    "\n",
    "        continuous_vars, optimal_power = optimize_continuous_vars(discrete_vars, cooling_load, current_state, prev_chiller_modes, chiller_tracker)\n",
    "        optimal_inputs = discrete_vars + continuous_vars\n",
    "        constraints_values = constraints(optimal_inputs, current_state, cooling_load, prev_chiller_modes, chiller_tracker)\n",
    "        print(\"Debug: Constraints:\", constraints_values)\n",
    "        if any(c < 0 for c in constraints_values):\n",
    "            print(\"Warning: Final solution violates constraints!\")\n",
    "            for i, c in enumerate(constraints_values):\n",
    "                if c < 0:\n",
    "                    print(f\"Constraint {i} violated: {c}\")\n",
    "        print(\"\\nDebug: Optimal inputs:\", optimal_inputs)\n",
    "        print(f\"Optimal power: {optimal_power}\")\n",
    "        print(f\"Final chiller modes: {discrete_vars}\")\n",
    "        print(f\"Final CHW setpoints: {continuous_vars[:N_CHILLERS]}\")\n",
    "        print(f\"Final CHW flows: {continuous_vars[N_CHILLERS:2*N_CHILLERS]}\")\n",
    "        print(f\"Final CDW flows: {continuous_vars[2*N_CHILLERS:]}\")\n",
    "\n",
    "        next_state, actual_power = system_model(current_state, optimal_inputs, cooling_load)\n",
    "        \n",
    "        all_changed = True\n",
    "        for i in range(N_CHILLERS):\n",
    "            if chiller_tracker.can_change(i) == 0:\n",
    "                all_changed = False\n",
    "        if not all_changed:\n",
    "            for i in range(N_CHILLERS):\n",
    "                if discrete_vars[i] != prev_chiller_modes[i]:\n",
    "                    if chiller_tracker.can_change(i):\n",
    "                        chiller_tracker.record_change(i)\n",
    "        \n",
    "        optimal_trajectory.append((optimal_inputs, actual_power))\n",
    "        # current_state = next_state.copy()  # Make sure to copy the state\n",
    "        prev_chiller_modes = discrete_vars.copy()  # Make sure to copy the modes\n",
    "\n",
    "    return optimal_trajectory\n",
    "\n",
    "# Run the optimization\n",
    "initial_state = {\n",
    "    'outdoor_weather_station_wetbulb_temperature': data.iloc[0]['outdoor_weather_station_wetbulb_temperature'],\n",
    "    'outdoor_weather_station_drybulb_temperature': data.iloc[0]['outdoor_weather_station_drybulb_temperature'],\n",
    "    'outdoor_weather_station_relative_humidity': data.iloc[0]['outdoor_weather_station_relative_humidity'],\n",
    "    'plant_target_chw_setpoint': data.iloc[0]['plant_target_chw_setpoint'],\n",
    "    'new_day': 0\n",
    "}\n",
    "\n",
    "optimal_trajectory = mpc_control(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('mpc_control(initial_state)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualize results\n",
    "actual_power = data['plant_power'].values\n",
    "predicted_power = [t[1] for t in optimal_trajectory]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actual_power, label='Actual Power')\n",
    "plt.plot(predicted_power, label='Optimized Power')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Optimized Power Consumption')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power (kW)')\n",
    "plt.show()\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (sum(actual_power) - sum(predicted_power)) / sum(actual_power) * 100\n",
    "print(f\"Total power consumption reduction: {improvement:.2f}%\")\n",
    "\n",
    "# Visualize chiller modes\n",
    "chiller_modes = np.array([t[0][:N_CHILLERS] for t in optimal_trajectory])\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(N_CHILLERS):\n",
    "    plt.plot(chiller_modes[:, i], label=f'Chiller {i+1}')\n",
    "plt.legend()\n",
    "plt.title('Chiller Operation Modes')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('On/Off')\n",
    "plt.yticks([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Visualize setpoints and flows\n",
    "setpoints = np.array([t[0][N_CHILLERS:2*N_CHILLERS] for t in optimal_trajectory])\n",
    "chw_flows = np.array([t[0][2*N_CHILLERS:3*N_CHILLERS] for t in optimal_trajectory])\n",
    "cdw_flows = np.array([t[0][3*N_CHILLERS:] for t in optimal_trajectory])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(N_CHILLERS):\n",
    "    plt.plot(setpoints[:, i], label=f'Chiller {i+1} Setpoint')\n",
    "plt.legend()\n",
    "plt.title('Chiller Setpoints')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature (°F)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(N_CHILLERS):\n",
    "    plt.plot(chw_flows[:, i], label=f'Chiller {i+1} CHW Flow')\n",
    "plt.legend()\n",
    "plt.title('Chilled Water Flow Rates')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Flow Rate (GPM)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(N_CHILLERS):\n",
    "    plt.plot(cdw_flows[:, i], label=f'Chiller {i+1} CDW Flow')\n",
    "plt.legend()\n",
    "plt.title('Condenser Water Flow Rates')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Flow Rate (GPM)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLotly plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Actual vs Optimized Power Consumption\n",
    "fig1 = go.Figure()\n",
    "\n",
    "# Add Actual Power trace\n",
    "fig1.add_trace(go.Scatter(x=np.arange(len(actual_power)), y=actual_power, mode='lines', name='Actual Power'))\n",
    "\n",
    "# Add Optimized Power trace\n",
    "fig1.add_trace(go.Scatter(x=np.arange(len(predicted_power)), y=predicted_power, mode='lines', name='Optimized Power'))\n",
    "\n",
    "# Update layout\n",
    "fig1.update_layout(\n",
    "    title='Actual vs Optimized Power Consumption',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Power (kW)',\n",
    "    legend=dict(x=0, y=1, traceorder='normal'),\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvement\n",
    "improvement = (sum(actual_power) - sum(predicted_power)) / sum(actual_power) * 100\n",
    "\n",
    "print(f\"Total power consumption reduction: {improvement:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiller Operation Modes\n",
    "fig2 = go.Figure()\n",
    "\n",
    "# Add traces for each chiller mode\n",
    "for i in range(N_CHILLERS):\n",
    "    fig2.add_trace(go.Scatter(x=np.arange(len(chiller_modes)), y=chiller_modes[:, i], mode='lines', name=f'Chiller {i+1}'))\n",
    "\n",
    "# Update layout\n",
    "fig2.update_layout(\n",
    "    title='Chiller Operation Modes',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='On/Off',\n",
    "    legend=dict(x=0, y=1, traceorder='normal'),\n",
    "    yaxis=dict(tickvals=[0, 1]),\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiller Setpoints\n",
    "fig3 = go.Figure()\n",
    "\n",
    "# Add traces for each chiller setpoint\n",
    "for i in range(N_CHILLERS):\n",
    "    fig3.add_trace(go.Scatter(x=np.arange(len(setpoints)), y=setpoints[:, i], mode='lines', name=f'Chiller {i+1} Setpoint'))\n",
    "\n",
    "# Update layout\n",
    "fig3.update_layout(\n",
    "    title='Chiller Setpoints',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Temperature (°F)',\n",
    "    legend=dict(x=1, y=1, traceorder='normal'),  # Move legend to top right corner\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assuming setpoints and chw_flows are available\n",
    "# Calculate total setpoint weighted by flow rate and handle division by zero\n",
    "total_setpoint_weighted = np.sum(setpoints * chw_flows / np.maximum(np.sum(chw_flows, axis=1, keepdims=True), 1e-6), axis=1)\n",
    "total_actual_chws = data['plant_target_chw_setpoint']  # Replace with your actual CHWS data\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for total setpoint weighted and total actual CHWS\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(total_setpoint_weighted)), y=total_setpoint_weighted, mode='lines', name='Total Setpoint Weighted'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(total_actual_chws)), y=total_actual_chws, mode='lines', name='Total Actual CHWS'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Total Target Setpoint (Weighted by Flow) vs Actual CHWS',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Temperature (°F)',\n",
    "    legend=dict(x=1, y=1, traceorder='normal'),  # Move legend to top right corner\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assuming cooling_load, chw_flows, and setpoints are available\n",
    "# Calculate total setpoint weighted by flow rate and handle division by zero\n",
    "total_setpoint_weighted = np.sum(setpoints * chw_flows / np.maximum(np.sum(chw_flows, axis=1, keepdims=True), 1e-6), axis=1)\n",
    "\n",
    "# Calculate optimized CHWR\n",
    "chw_flows_sum = np.sum(chw_flows, axis=1)\n",
    "optimized_chwr = (data['plant_cooling_rate'] * 24) / np.where(chw_flows_sum != 0, chw_flows_sum, 1e-6) + total_setpoint_weighted\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add trace for optimized CHWR\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(optimized_chwr)), y=optimized_chwr, mode='lines', name='Optimized CHWR'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Optimized CHWR',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Temperature (°F)',\n",
    "    legend=dict(x=1, y=1, traceorder='normal'),  # Move legend to top right corner\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chilled Water Flow Rates\n",
    "fig4 = go.Figure()\n",
    "\n",
    "# Add traces for each chiller CHW flow rate\n",
    "for i in range(N_CHILLERS):\n",
    "    fig4.add_trace(go.Scatter(x=np.arange(len(chw_flows)), y=chw_flows[:, i], mode='lines', name=f'Chiller {i+1} CHW Flow'))\n",
    "\n",
    "# Update layout\n",
    "fig4.update_layout(\n",
    "    title='Chilled Water Flow Rates',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Flow Rate (GPM)',\n",
    "    legend=dict(x=1, y=1, traceorder='normal'),  # Move legend to top right corner\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condenser Water Flow Rates\n",
    "fig5 = go.Figure()\n",
    "\n",
    "# Add traces for each chiller CDW flow rate\n",
    "for i in range(N_CHILLERS):\n",
    "    fig5.add_trace(go.Scatter(x=np.arange(len(cdw_flows)), y=cdw_flows[:, i], mode='lines', name=f'Chiller {i+1} CDW Flow'))\n",
    "\n",
    "# Update layout\n",
    "fig5.update_layout(\n",
    "    title='Condenser Water Flow Rates',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Flow Rate (GPM)',\n",
    "    legend=dict(x=1, y=1, traceorder='normal'),  # Move legend to top right corner\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig5.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Calculate plant efficiency from actual and optimized power\n",
    "actual_power = data['plant_power'].values\n",
    "predicted_power = [t[1] for t in optimal_trajectory]  # Assuming optimal_trajectory contains optimized power\n",
    "actual_cooling_rate = data['plant_cooling_rate'].values  # Cooling rate in tons\n",
    "\n",
    "# Calculate efficiency (kW/ton)\n",
    "actual_efficiency = actual_power / actual_cooling_rate\n",
    "optimized_efficiency = np.array(predicted_power) / actual_cooling_rate\n",
    "\n",
    "# Plant Efficiency Plot\n",
    "fig_efficiency = go.Figure()\n",
    "\n",
    "# Add actual efficiency trace\n",
    "fig_efficiency.add_trace(go.Scatter(x=np.arange(len(actual_efficiency)), y=actual_efficiency, mode='lines', name='Actual Efficiency'))\n",
    "\n",
    "# Add optimized efficiency trace\n",
    "fig_efficiency.add_trace(go.Scatter(x=np.arange(len(optimized_efficiency)), y=optimized_efficiency, mode='lines', name='Optimized Efficiency'))\n",
    "\n",
    "# Update layout\n",
    "fig_efficiency.update_layout(\n",
    "    title='Plant Efficiency: Actual vs Optimized',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Efficiency (kW/ton)',\n",
    "    legend=dict(x=0, y=1, traceorder='normal'),\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig_efficiency.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altotech-ml-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
