{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load columns_info.json\n",
    "with open('../data/columns_info.json') as f:\n",
    "    columns_info = json.load(f)\n",
    "\n",
    "# Load chiller_plant_dataset.parquet\n",
    "chiller_data = pd.read_parquet('../data/chiller_plant_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data_raw = pd.read_parquet('../data/chiller_plant_dataset.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "column_list = chiller_data.columns.to_list()\n",
    "columns_info_list = []\n",
    "for key in columns_info:\n",
    "    tup = ast.literal_eval(key)\n",
    "    columns_info_list.append(tup)\n",
    "columns_to_drop = [col for col in column_list if col not in columns_info_list]\n",
    "columns_to_drop.append(('chiller_6', 'power'))\n",
    "chiller_data = chiller_data.drop(columns=columns_to_drop)\n",
    "chiller_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.ffill(inplace=True)\n",
    "chiller_data.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns have negative values\n",
    "negative_columns = chiller_data.columns[chiller_data.lt(0).any()]\n",
    "\n",
    "# Count negative values in each column\n",
    "negative_counts = chiller_data[negative_columns].lt(0).sum().sum()\n",
    "\n",
    "print(\"negative values:\")\n",
    "print(negative_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative values with NaN\n",
    "chiller_data[negative_columns] = chiller_data[negative_columns].mask(chiller_data[negative_columns] < 0)\n",
    "# Forward fill NaN values\n",
    "chiller_data.ffill(inplace=True)\n",
    "chiller_data.bfill(inplace=True)\n",
    "\n",
    "# Verify if negative values are replaced\n",
    "negative_counts_after_fill = chiller_data[negative_columns].lt(0).sum().sum()\n",
    "\n",
    "print(\"negative values after forward filling:\")\n",
    "print(negative_counts_after_fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target = power consumption of chiller/pump/cooling tower \n",
    "\n",
    "feature = others variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_columns = [col for col in chiller_data.columns if 'power' in col[1]]\n",
    "chiller_data[power_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "is_device = ['chiller', 'cdp', 'chp', 'ct']\n",
    "feature_columns = [col for col in chiller_data.columns if col[0] == 'chiller_1' and col[1] != 'power']\n",
    "feature_columns = [col for col in chiller_data.columns \n",
    "                   if (col[0].split('_')[0] not in is_device and 'power' not in col[1]) \n",
    "                   or col in feature_columns]\n",
    "\n",
    "# Check the number of selected feature columns\n",
    "num_features = len(feature_columns)\n",
    "print(f\"Number of feature columns: {num_features}\")\n",
    "\n",
    "# Extract the feature data\n",
    "features_data = chiller_data[feature_columns]\n",
    "\n",
    "# Calculate the Spearman correlation matrix\n",
    "spearman_corr_matrix = features_data.corr(method='spearman')\n",
    "\n",
    "# Display the Spearman correlation matrix\n",
    "print(spearman_corr_matrix)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(spearman_corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# Set the title\n",
    "plt.title('Spearman Correlation Matrix', size=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Find pairs with absolute correlation greater than 0.7\n",
    "threshold = 0.7\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(spearman_corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(spearman_corr_matrix.columns)):\n",
    "        corr_value = spearman_corr_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > threshold:\n",
    "            feature_pair = (spearman_corr_matrix.columns[i], spearman_corr_matrix.columns[j], corr_value)\n",
    "            high_corr_pairs.append(feature_pair)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "high_corr_pairs_df = pd.DataFrame(high_corr_pairs, columns=['Feature 1', 'Feature 2', 'Correlation'])\n",
    "\n",
    "print(high_corr_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "is_device = ['chiller', 'cdp', 'chp', 'ct']\n",
    "feature_columns = [col for col in chiller_data.columns \n",
    "                   if col[0] == 'chiller_1' and col[1] != 'power']\n",
    "\n",
    "# Check the number of selected feature columns\n",
    "num_features = len(feature_columns)\n",
    "print(f\"Number of feature columns: {num_features}\")\n",
    "\n",
    "# Extract the feature data\n",
    "features_data = chiller_data[feature_columns]\n",
    "\n",
    "# Calculate the Spearman correlation matrix\n",
    "spearman_corr_matrix = features_data.corr(method='spearman')\n",
    "\n",
    "# Display the Spearman correlation matrix\n",
    "print(spearman_corr_matrix)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(spearman_corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# Set the title\n",
    "plt.title('Spearman Correlation Matrix', size=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation to power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of power columns\n",
    "power_columns = [col for col in chiller_data.columns if 'chiller' in col[0] and 'power' in col[1]]\n",
    "\n",
    "is_device = ['chiller', 'cdp', 'chp', 'ct']\n",
    "drop_properties = ['status_read', 'mode', 'current', 'setpoint_read']\n",
    "\n",
    "# Calculate and plot top 20 Spearman correlations for each power column\n",
    "for power_col in power_columns:\n",
    "    compare_columns = [ccol for ccol in chiller_data.columns if (ccol[0] == power_col[0] or ccol[0].split('_')[0] not in is_device)\n",
    "                       and 'power' not in ccol[1]]\n",
    "    compare_columns = [ccol for ccol in compare_columns if ccol[1] not in drop_properties]\n",
    "    \n",
    "    X = chiller_data[compare_columns]\n",
    "    y = chiller_data[power_col]\n",
    "    \n",
    "    # Calculate Spearman correlation\n",
    "    correlations = X.apply(lambda col: col.corr(y, method='spearman'))\n",
    "    corr_series = correlations.sort_values(ascending=False)\n",
    "    corr_series.index = ['_'.join(col) if isinstance(col, tuple) else col for col in corr_series.index]\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.barplot(x=corr_series.values, y=corr_series.index)\n",
    "    plt.title(f'Top 20 Spearman Correlations with {power_col}')\n",
    "    plt.xlabel('Spearman Correlation')\n",
    "    plt.ylabel('Variables')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr Chiller_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of power columns\n",
    "power_columns = [col for col in chiller_data.columns if 'chiller' in col[0] and 'power' in col[1]]\n",
    "\n",
    "\n",
    "# Calculate and plot top 20 Spearman correlations for each power column\n",
    "for power_col in power_columns:\n",
    "    compare_columns = [ccol for ccol in chiller_data.columns if ccol[0]==power_col[0]\n",
    "                       and 'power' not in ccol[1]]\n",
    "    \n",
    "    X = chiller_data[compare_columns]\n",
    "    y = chiller_data[power_col]\n",
    "    \n",
    "    # Calculate Spearman correlation\n",
    "    correlations = X.apply(lambda col: col.corr(y, method='spearman'))\n",
    "    corr_series = correlations.sort_values(ascending=False)\n",
    "    corr_series.index = ['_'.join(col) if isinstance(col, tuple) else col for col in corr_series.index]\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.barplot(x=corr_series.values, y=corr_series.index)\n",
    "    plt.title(f'Top 20 Spearman Correlations with {power_col}')\n",
    "    plt.xlabel('Spearman Correlation')\n",
    "    plt.ylabel('Variables')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of power columns\n",
    "power_columns = [col for col in chiller_data.columns if 'chiller' in col[0] and 'power' in col[1]]\n",
    "\n",
    "is_device = ['chiller','cdp','chp','ct']\n",
    "drop_properties = ['status_read','mode','current','setpoint_read']\n",
    "\n",
    "# Calculate and plot top 20 mutual information for each power column\n",
    "for power_col in power_columns:\n",
    "    compare_columns = [ccol for ccol in chiller_data.columns if (ccol[0]==power_col[0] or ccol[0].split('_')[0] not in is_device)\n",
    "                       and 'power' not in ccol[1]]\n",
    "    compare_columns = [ccol for ccol in compare_columns if ccol[1] not in drop_properties]\n",
    "    X = chiller_data[compare_columns]\n",
    "    y = chiller_data[power_col]\n",
    "    \n",
    "    mi = mutual_info_regression(X, y)\n",
    "    mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "    mi_series.index = ['_'.join(col) if isinstance(col, tuple) else col for col in mi_series.index]\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.barplot(x=mi_series.values, y=mi_series.index)\n",
    "    plt.title(f'Top 20 Mutual Information with {power_col}')\n",
    "    plt.xlabel('Mutual Information')\n",
    "    plt.ylabel('Variables')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['chiller_1','power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['chiller_2','power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['chiller_3','power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['chiller_4','power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['chiller_5','power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['plant','power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['plant','power_all_chillers'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['plant','power_all_cts'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['plant','power_all_cdps'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=chiller_data.index, y=chiller_data['plant','power_all_chps'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr plant power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of power columns\n",
    "power_columns = [col for col in chiller_data.columns if 'plant' in col[0] and 'power' in col[1]]\n",
    "\n",
    "is_device = ['chiller', 'cdp', 'chp', 'ct']\n",
    "drop_properties = ['status_read', 'mode', 'current', 'setpoint_read']\n",
    "\n",
    "# Calculate and plot top 20 Spearman correlations for each power column\n",
    "for power_col in power_columns:\n",
    "    compare_columns = [ccol for ccol in chiller_data.columns if (ccol[0] == power_col[0] or ccol[0].split('_')[0] not in is_device)\n",
    "                       and 'power' not in ccol[1]]\n",
    "    compare_columns = [ccol for ccol in compare_columns if ccol[1] not in drop_properties]\n",
    "    \n",
    "    X = chiller_data[compare_columns]\n",
    "    y = chiller_data[power_col]\n",
    "    \n",
    "    # Calculate Spearman correlation\n",
    "    correlations = X.apply(lambda col: col.corr(y, method='spearman'))\n",
    "    corr_series = correlations.sort_values(ascending=False)\n",
    "    corr_series.index = ['_'.join(col) if isinstance(col, tuple) else col for col in corr_series.index]\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.barplot(x=corr_series.values, y=corr_series.index)\n",
    "    plt.title(f'Top 20 Spearman Correlations with {power_col}')\n",
    "    plt.xlabel('Spearman Correlation')\n",
    "    plt.ylabel('Variables')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Info Plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of power columns\n",
    "power_columns = [col for col in chiller_data.columns if 'plant' in col[0] and 'power' in col[1]]\n",
    "\n",
    "is_device = ['chiller', 'cdp', 'chp', 'ct']\n",
    "drop_properties = ['status_read', 'mode', 'current', 'setpoint_read']\n",
    "\n",
    "# Calculate and plot top 20 Spearman correlations for each power column\n",
    "for power_col in power_columns:\n",
    "    compare_columns = [ccol for ccol in chiller_data.columns if (ccol[0] == power_col[0] or ccol[0].split('_')[0] not in is_device)\n",
    "                       and 'power' not in ccol[1]]\n",
    "    compare_columns = [ccol for ccol in compare_columns if ccol[1] not in drop_properties]\n",
    "    \n",
    "    X = chiller_data[compare_columns]\n",
    "    y = chiller_data[power_col]\n",
    "    \n",
    "    mi = mutual_info_regression(X, y)\n",
    "    mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "    mi_series.index = ['_'.join(col) if isinstance(col, tuple) else col for col in mi_series.index]\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.barplot(x=mi_series.values, y=mi_series.index)\n",
    "    plt.title(f'Top 20 Mutual Information with {power_col}')\n",
    "    plt.xlabel('Mutual Information')\n",
    "    plt.ylabel('Variables')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select proper feature from EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneccesary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For chilller:\n",
    "\n",
    "    Target: power\n",
    "\n",
    "    Feature to keep\n",
    "\n",
    "        cooling_rate ?\n",
    "\n",
    "        cond_leaving_water_temperature\n",
    "\n",
    "        cond_entering_water_temperature\n",
    "\n",
    "        evap_leaving_water_temperature\n",
    "\n",
    "        evap_entering_water_temperature\n",
    "\n",
    "        cond_water_flow_rate\n",
    "\n",
    "        evap_water_flow_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiller_data_fit = chiller_data.copy()\n",
    "chiller_data_fit.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in chiller_data_fit.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chiller_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ch1_feature = [col for col in chiller_data_fit.columns if 'chiller_1' in col]\n",
    "\n",
    "ch1_feature = ['chiller_1_evap_leaving_water_temperature',\n",
    "               'chiller_1_evap_entering_water_temperature',\n",
    "               'chiller_1_cond_leaving_water_temperature',\n",
    "               'chiller_1_cond_entering_water_temperature',\n",
    "               'chiller_1_evap_water_flow_rate',\n",
    "               'chiller_1_cond_water_flow_rate']\n",
    "\n",
    "ch1_target = ['chiller_1_power']\n",
    "\n",
    "X = chiller_data_fit[ch1_feature]\n",
    "y = chiller_data_fit[ch1_target]\n",
    "\n",
    "X_train, y_train = X[:int(0.6*len(X))], y[:int(0.6*len(y))]\n",
    "X_test, y_test = X[int(0.6*len(X)):], y[int(0.6*len(y)):]\n",
    "\n",
    "# Train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Performance\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_df = pd.DataFrame(y_pred_lr, index=y_test.index, columns=y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=X_test.index, y=y_pred_lr_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clipped Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ch1_feature = [col for col in chiller_data_fit.columns if 'chiller_1' in col]\n",
    "\n",
    "ch1_feature = ['chiller_1_evap_leaving_water_temperature',\n",
    "               'chiller_1_evap_entering_water_temperature',\n",
    "               'chiller_1_cond_leaving_water_temperature',\n",
    "               'chiller_1_cond_entering_water_temperature',\n",
    "               'chiller_1_evap_water_flow_rate',\n",
    "               'chiller_1_cond_water_flow_rate']\n",
    "\n",
    "ch1_target = ['chiller_1_power']\n",
    "\n",
    "X = chiller_data_fit[ch1_feature]\n",
    "y = chiller_data_fit[ch1_target]\n",
    "\n",
    "X_train, y_train = X[:int(0.6*len(X))], y[:int(0.6*len(y))]\n",
    "X_test, y_test = X[int(0.6*len(X)):], y[int(0.6*len(y)):]\n",
    "\n",
    "# Train the model\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Performance\n",
    "mse_lr = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n",
    "\n",
    "y_pred_ridge_clipped = y_pred_ridge.clip(min=0)\n",
    "# Performance after clipping\n",
    "mse_ridge_clipped = mean_squared_error(y_test, y_pred_ridge_clipped)\n",
    "print(f\"Ridge Regression MSE after Clipping: {mse_ridge_clipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge_df = pd.DataFrame(y_pred_ridge, index=y_test.index, columns=y_test.columns)\n",
    "y_pred_ridge_clipped_df = pd.DataFrame(y_pred_ridge_clipped, index=y_test.index, columns=y_test.columns)\n",
    "fig = px.line(x=X_test.index, y=y_pred_ridge_clipped_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "ch1_feature = ['chiller_1_evap_leaving_water_temperature',\n",
    "               'chiller_1_evap_entering_water_temperature',\n",
    "               'chiller_1_cond_leaving_water_temperature',\n",
    "               'chiller_1_cond_entering_water_temperature',\n",
    "               'chiller_1_evap_water_flow_rate',\n",
    "               'chiller_1_cond_water_flow_rate']\n",
    "\n",
    "ch1_target = ['chiller_1_power']\n",
    "\n",
    "X = chiller_data_fit[ch1_feature]\n",
    "y = chiller_data_fit[ch1_target]\n",
    "\n",
    "X_train, y_train = X[:int(0.6*len(X))], y[:int(0.6*len(y))]\n",
    "X_test, y_test = X[int(0.6*len(X)):], y[int(0.6*len(y)):]\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(n_estimators=400,\n",
    "                           max_depth=30,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=6, \n",
    "                           random_state=42, \n",
    "                           bootstrap=True)\n",
    "rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "# Clipping negative predictions to zero\n",
    "y_pred_rf_clipped = y_pred_rf.clip(min=0)\n",
    "\n",
    "# Performance after clipping\n",
    "mse_rf_clipped = mean_squared_error(y_test, y_pred_rf_clipped)\n",
    "print(f\"Random Forest MSE after Clipping: {mse_rf_clipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_clipped_df = pd.DataFrame(y_pred_rf_clipped, index=y_test.index, columns=y_test.columns)\n",
    "fig = px.line(x=X_test.index, y=y_pred_rf_clipped_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10, 12],\n",
    "    'min_samples_leaf': [2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "                           max_depth=30, \n",
    "                           random_state=42, \n",
    "                           bootstrap=True)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                          cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Use the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Performance\n",
    "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
    "print(f\"Random Forest MSE (Best Model): {mse_best_rf}\")\n",
    "\n",
    "# Clipping negative predictions to zero\n",
    "y_pred_best_rf_clipped = y_pred_best_rf.clip(min=0)\n",
    "\n",
    "# Performance after clipping\n",
    "mse_best_rf_clipped = mean_squared_error(y_test, y_pred_best_rf_clipped)\n",
    "print(f\"Random Forest MSE after Clipping (Best Model): {mse_best_rf_clipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best_rf_clipped_df = pd.DataFrame(y_pred_best_rf_clipped, index=y_test.index, columns=y_test.columns)\n",
    "fig = px.line(x=X_test.index, y=y_pred_best_rf_clipped_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ARIMA Regression with predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SARIMAX Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "ch1_feature = [\n",
    "    'chiller_1_evap_leaving_water_temperature',\n",
    "    'chiller_1_evap_entering_water_temperature',\n",
    "    'chiller_1_cond_leaving_water_temperature',\n",
    "    'chiller_1_cond_entering_water_temperature',\n",
    "    'chiller_1_evap_water_flow_rate',\n",
    "    'chiller_1_cond_water_flow_rate'\n",
    "]\n",
    "\n",
    "ch1_target = ['chiller_1_power']\n",
    "\n",
    "X = chiller_data_fit[ch1_feature]\n",
    "y = chiller_data_fit[ch1_target]\n",
    "\n",
    "# Ensure the index has a datetime frequency\n",
    "X.index = pd.to_datetime(X.index)\n",
    "y.index = pd.to_datetime(y.index)\n",
    "X.index.freq = pd.infer_freq(X.index)\n",
    "y.index.freq = pd.infer_freq(y.index)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "train_size = int(0.6 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the SARIMAX model\n",
    "model = SARIMAX(endog=y_train, exog=X_train, order=(2, 1, 3), seasonal_order=(0,0,0,0))\n",
    "\n",
    "# Fit the SARIMAX model\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficients of the SARIMAX model:\")\n",
    "print(fitted_model.params)\n",
    "\n",
    "# Print the summary of the fitted model\n",
    "print(fitted_model.summary())\n",
    "\n",
    "\n",
    "# Forecast using the SARIMAX model\n",
    "forecast = fitted_model.forecast(steps=len(X_test), exog=X_test)\n",
    "#forecast = np.maximum(forecast, 0)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_sarimax = mean_squared_error(y_test, forecast)\n",
    "print(f\"SARIMAX MSE: {mse_sarimax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(forecast.values, index=y_test.index, columns=y_test.columns)\n",
    "fig = px.line(x=X_test.index, y=forecast_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SARIMAX with log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define features and target\n",
    "ch1_feature = [\n",
    "    'chiller_1_evap_leaving_water_temperature',\n",
    "    'chiller_1_evap_entering_water_temperature',\n",
    "    'chiller_1_cond_leaving_water_temperature',\n",
    "    'chiller_1_cond_entering_water_temperature',\n",
    "    'chiller_1_evap_water_flow_rate',\n",
    "    'chiller_1_cond_water_flow_rate'\n",
    "]\n",
    "\n",
    "ch1_target = ['chiller_1_power']\n",
    "\n",
    "X = chiller_data_fit[ch1_feature]\n",
    "y = chiller_data_fit[ch1_target]\n",
    "\n",
    "# Apply log transformation to the target variable to ensure non-negative predictions\n",
    "y_log = np.log1p(y)  # log1p is used to avoid log(0) issues\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "train_size = int(0.6 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train_log, y_test_log = y_log[:train_size], y_log[train_size:]\n",
    "\n",
    "# Define the SARIMAX model\n",
    "model = SARIMAX(endog=y_train_log, exog=X_train, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "\n",
    "# Fit the SARIMAX model\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Forecast using the SARIMAX model\n",
    "forecast_log = fitted_model.forecast(steps=len(X_test), exog=X_test)\n",
    "\n",
    "# Transform the predictions back to the original scale\n",
    "forecast = np.expm1(forecast_log)  # expm1 is the inverse of log1p\n",
    "\n",
    "# Calculate MSE\n",
    "mse_sarimax = mean_squared_error(y_test, forecast)\n",
    "print(f\"SARIMAX MSE: {mse_sarimax}\")\n",
    "\n",
    "# Ensure predictions are non-negative\n",
    "# forecast = np.maximum(forecast, 0)\n",
    "mse_sarimax_clipped = mean_squared_error(y_test, forecast)\n",
    "print(f\"SARIMAX MSE after clipping: {mse_sarimax_clipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(forecast.values, index=y_test.index, columns=y_test.columns)\n",
    "fig = px.line(x=X_test.index, y=forecast_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SARIMAX feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "ch1_feature = [\n",
    "    'chiller_1_evap_leaving_water_temperature',\n",
    "    'chiller_1_evap_entering_water_temperature',\n",
    "    'chiller_1_cond_leaving_water_temperature',\n",
    "    'chiller_1_cond_entering_water_temperature',\n",
    "    'chiller_1_evap_water_flow_rate',\n",
    "    'chiller_1_cond_water_flow_rate',\n",
    "    'chiller_1_demand_limit_setpoint_read'\n",
    "]\n",
    "\n",
    "ch1_target = ['chiller_1_power']\n",
    "\n",
    "X = chiller_data_fit[ch1_feature]\n",
    "y = chiller_data_fit[ch1_target]\n",
    "\n",
    "# Ensure the index has a datetime frequency\n",
    "X.index = pd.to_datetime(X.index)\n",
    "y.index = pd.to_datetime(y.index)\n",
    "X.index.freq = pd.infer_freq(X.index)\n",
    "y.index.freq = pd.infer_freq(y.index)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "train_size = int(0.6 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "decomposition = seasonal_decompose(y, period=1)  # Adjust period based on your data's seasonal cycle\n",
    "# Plot seasonal components\n",
    "decomposition.plot()\n",
    "plt.show()\n",
    "\n",
    "# ACF and PACF plots\n",
    "plot_acf(y)\n",
    "plot_pacf(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SARIMAX model\n",
    "model = SARIMAX(endog=y_train, exog=X_train, order=(2, 1, 3), seasonal_order=(0,0,0,0))\n",
    "\n",
    "# Fit the SARIMAX model\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficients of the SARIMAX model:\")\n",
    "print(fitted_model.params)\n",
    "\n",
    "# Print the summary of the fitted model\n",
    "print(fitted_model.summary())\n",
    "\n",
    "\n",
    "# Forecast using the SARIMAX model\n",
    "forecast = fitted_model.forecast(steps=len(X_test), exog=X_test)\n",
    "#forecast = np.maximum(forecast, 0)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_sarimax = mean_squared_error(y_test, forecast)\n",
    "print(f\"SARIMAX MSE: {mse_sarimax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = np.maximum(forecast, 0)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_sarimax = mean_squared_error(y_test, forecast)\n",
    "print(f\"SARIMAX MSE: {mse_sarimax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(forecast.values, index=y_test.index, columns=y_test.columns)\n",
    "fig = px.line(x=X_test.index, y=forecast_df['chiller_1_power'])\n",
    "fig.update_traces(line_color='red', name='Chiller 1 Power')\n",
    "fig.add_trace(px.line(x=X_test.index, y=y_test['chiller_1_power']).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Identification Plant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "plant_features = {'plant_power':['condenser_water_loop_flow_rate',\n",
    "                                 'chilled_water_loop_flow_rate',\n",
    "                                 'condenser_water_loop_water_delta_temperature',\n",
    "                                 'chilled_water_loop_water_delta_temperature',\n",
    "                                 'plant_number_of_running_chps'],\n",
    "                    'plant_power_all_cdps':['plant_avg_cdp_speed',\n",
    "                                          'condenser_water_loop_flow_rate'],\n",
    "                    'plant_power_all_chps':['plant_avg_chp_speed',\n",
    "                                          'chilled_water_loop_flow_rate'],\n",
    "                    'plant_power_all_chillers':['condenser_water_loop_flow_rate',\n",
    "                                 'chilled_water_loop_flow_rate',\n",
    "                                 'condenser_water_loop_water_delta_temperature',\n",
    "                                 'chilled_water_loop_water_delta_temperature',],\n",
    "                    'plant_power_all_cts':['condenser_water_loop_flow_rate',\n",
    "                                           'plant_number_of_running_cts',\n",
    "                                           'plant_avg_ct_speed',\n",
    "                                           'condenser_water_loop_water_delta_temperature']}\n",
    "\n",
    "plant_targets = [[col] for col in chiller_data_fit.columns if 'plant' in col and 'power' in col]\n",
    "\n",
    "for target in plant_targets:\n",
    "    X = chiller_data_fit[plant_features[target[0]]]\n",
    "    y = chiller_data_fit[target]\n",
    "\n",
    "    X_train, y_train = X[:int(0.6*len(X))], y[:int(0.6*len(y))]\n",
    "    X_test, y_test = X[int(0.6*len(X)):], y[int(0.6*len(y)):]\n",
    "    # Random Forest Model\n",
    "    rf_model = RandomForestRegressor(n_estimators=400,\n",
    "                           max_depth=30,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=6, \n",
    "                           random_state=42, \n",
    "                           bootstrap=True)\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "    # Clipping negative predictions to zero\n",
    "    y_pred_rf_clipped = y_pred_rf.clip(min=0)\n",
    "\n",
    "    # Performance after clipping\n",
    "    mse_rf_clipped = mean_squared_error(y_test, y_pred_rf_clipped)\n",
    "    print(f\"Random Forest MSE after Clipping: {mse_rf_clipped}\")\n",
    "    y_pred_rf_clipped_df = pd.DataFrame(y_pred_rf_clipped, index=y_test.index, columns=y_test.columns)\n",
    "    fig = px.line(x=X_test.index, y=y_pred_rf_clipped_df[target[0]], title=f'{target}')\n",
    "    fig.update_traces(line_color='red', name=f'{target}')\n",
    "    fig.add_trace(px.line(x=X_test.index, y=y_test[target[0]]).data[0])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly.express as px\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the function to create lagged features\n",
    "def create_lagged_features(df, target_col, lag, exog_cols):\n",
    "    df_lagged = df.copy()\n",
    "    for l in range(1, lag + 1):\n",
    "        df_lagged[f'{target_col}_lag{l}'] = df[target_col].shift(l)\n",
    "        for exog_col in exog_cols:\n",
    "            df_lagged[f'{exog_col}_lag{l}'] = df[exog_col].shift(l)\n",
    "    df_lagged = df_lagged.dropna()\n",
    "    return df_lagged\n",
    "\n",
    "# Parameters\n",
    "lag = 3  # Number of lags to use\n",
    "\n",
    "plant_features = {'plant_power': ['condenser_water_loop_flow_rate',\n",
    "                                  'chilled_water_loop_flow_rate',\n",
    "                                  'condenser_water_loop_water_delta_temperature',\n",
    "                                  'chilled_water_loop_water_delta_temperature',\n",
    "                                  'plant_number_of_running_chps'],\n",
    "                  'plant_power_all_cdps': ['plant_avg_cdp_speed',\n",
    "                                           'condenser_water_loop_flow_rate'],\n",
    "                  'plant_power_all_chps': ['plant_avg_chp_speed',\n",
    "                                           'chilled_water_loop_flow_rate'],\n",
    "                  'plant_power_all_chillers': ['condenser_water_loop_flow_rate',\n",
    "                                               'chilled_water_loop_flow_rate',\n",
    "                                               'condenser_water_loop_water_delta_temperature',\n",
    "                                               'chilled_water_loop_water_delta_temperature'],\n",
    "                  'plant_power_all_cts': ['condenser_water_loop_flow_rate',\n",
    "                                          'plant_number_of_running_cts',\n",
    "                                          'plant_avg_ct_speed',\n",
    "                                          'condenser_water_loop_water_delta_temperature']}\n",
    "\n",
    "plant_targets = [[col] for col in chiller_data_fit.columns if 'plant' in col and 'power' in col]\n",
    "\n",
    "class NARXModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NARXModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, 50, batch_first=True)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "for target in plant_targets:\n",
    "    target_col = target[0]\n",
    "    exog_cols = plant_features[target_col]\n",
    "\n",
    "    use_cols = [col for col in chiller_data_fit.columns if col==target_col or col in exog_cols]\n",
    "    df_use = chiller_data_fit[use_cols]\n",
    "\n",
    "    # Create lagged features\n",
    "    df_use_lagged = create_lagged_features(df_use, target_col, lag, exog_cols)\n",
    "    X = df_use_lagged.drop(columns=[target_col])\n",
    "    y = df_use_lagged[target]\n",
    "\n",
    "    # Splitting the data into train and test sets\n",
    "    train_size = int(0.6 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "    # Calculate the correct number of features\n",
    "    num_features = X_train.shape[1] // (lag + 1)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_train_scaled shape before reshape: {X_train_scaled.shape}\")\n",
    "    print(f\"Expected reshape dimensions: ({X_train_scaled.shape[0]}, {lag + 1}, {num_features})\")\n",
    "\n",
    "    # Ensure the number of elements is divisible by the new shape\n",
    "    if X_train_scaled.size % (lag + 1 * num_features) != 0:\n",
    "        raise ValueError(f\"Cannot reshape array of size {X_train_scaled.size} into shape ({X_train_scaled.shape[0]}, {lag + 1}, {num_features})\")\n",
    "\n",
    "    # Reshape for LSTM\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], lag + 1, num_features))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], lag + 1, num_features))\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Define the model\n",
    "    model = NARXModel(input_dim=X_train_tensor.shape[2]).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Clipping negative predictions to zero\n",
    "    y_pred_clipped = y_pred.clip(min=0)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_clipped = mean_squared_error(y_test, y_pred_clipped)\n",
    "    print(f\"NARX MSE for {target_col}: {mse}\")\n",
    "    print(f\"NARX MSE after Clipping for {target_col}: {mse_clipped}\")\n",
    "\n",
    "    # Visualize the results\n",
    "    y_pred_clipped_df = pd.DataFrame(y_pred_clipped, index=y_test.index, columns=[target_col])\n",
    "    fig = px.line(x=X_test.index, y=y_pred_clipped_df[target_col], title=f'{target_col}')\n",
    "    fig.update_traces(line_color='red', name=f'{target_col}')\n",
    "    fig.add_trace(px.line(x=X_test.index, y=y_test[target_col]).data[0])\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly.express as px\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the function to create lagged features\n",
    "def create_lagged_features(df, target_col, lag, exog_cols):\n",
    "    df_lagged = df.copy()\n",
    "    for l in range(1, lag + 1):\n",
    "        df_lagged[f'{target_col}_lag{l}'] = df[target_col].shift(l)\n",
    "        for exog_col in exog_cols:\n",
    "            df_lagged[f'{exog_col}_lag{l}'] = df[exog_col].shift(l)\n",
    "    df_lagged = df_lagged.dropna()\n",
    "    return df_lagged\n",
    "\n",
    "# Parameters\n",
    "lag = 3  # Number of lags to use\n",
    "\n",
    "plant_features = {'plant_power': ['condenser_water_loop_flow_rate',\n",
    "                                  'chilled_water_loop_flow_rate',\n",
    "                                  'condenser_water_loop_water_delta_temperature',\n",
    "                                  'chilled_water_loop_water_delta_temperature',\n",
    "                                  'plant_number_of_running_chps'],\n",
    "                  'plant_power_all_cdps': ['plant_avg_cdp_speed',\n",
    "                                           'condenser_water_loop_flow_rate'],\n",
    "                  'plant_power_all_chps': ['plant_avg_chp_speed',\n",
    "                                           'chilled_water_loop_flow_rate'],\n",
    "                  'plant_power_all_chillers': ['condenser_water_loop_flow_rate',\n",
    "                                               'chilled_water_loop_flow_rate',\n",
    "                                               'condenser_water_loop_water_delta_temperature',\n",
    "                                               'chilled_water_loop_water_delta_temperature'],\n",
    "                  'plant_power_all_cts': ['condenser_water_loop_flow_rate',\n",
    "                                          'plant_number_of_running_cts',\n",
    "                                          'plant_avg_ct_speed',\n",
    "                                          'condenser_water_loop_water_delta_temperature']}\n",
    "\n",
    "plant_targets = [[col] for col in chiller_data_fit.columns if 'plant' in col and 'power' in col]\n",
    "\n",
    "class NARXModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NARXModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "for target in plant_targets:\n",
    "    target_col = target[0]\n",
    "    exog_cols = plant_features[target_col]\n",
    "\n",
    "    use_cols = [col for col in chiller_data_fit.columns if col==target_col or col in exog_cols]\n",
    "    df_use = chiller_data_fit[use_cols]\n",
    "\n",
    "    # Create lagged features\n",
    "    df_use_lagged = create_lagged_features(df_use, target_col, lag, exog_cols)\n",
    "    X = df_use_lagged.drop(columns=[target_col])\n",
    "    y = df_use_lagged[target]\n",
    "\n",
    "    # Splitting the data into train and test sets\n",
    "    train_size = int(0.6 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Define the model\n",
    "    model = NARXModel(input_dim=X_train_tensor.shape[1]).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Clipping negative predictions to zero\n",
    "    y_pred_clipped = y_pred.clip(min=0)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_clipped = mean_squared_error(y_test, y_pred_clipped)\n",
    "    print(f\"NARX MSE for {target_col}: {mse}\")\n",
    "    print(f\"NARX MSE after Clipping for {target_col}: {mse_clipped}\")\n",
    "\n",
    "    # Visualize the results\n",
    "    y_pred_clipped_df = pd.DataFrame(y_pred_clipped, index=y_test.index, columns=[target_col])\n",
    "    fig = px.line(x=X_test.index, y=y_pred_clipped_df[target_col], title=f'{target_col}')\n",
    "    fig.update_traces(line_color='red', name=f'{target_col}')\n",
    "    fig.add_trace(px.line(x=X_test.index, y=y_test[target_col]).data[0])\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altotech-ml-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
